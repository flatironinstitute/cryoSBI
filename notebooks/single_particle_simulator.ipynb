{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de16e975-19a1-47b9-aa77-0ec77b576c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cryo_sbi.wpa_simulator.image_generation import gen_quat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c6bc3-879f-4863-81fd-a4d955f39d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c54ae-e51a-4de4-a1f7-eab51cd91a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_params = {\n",
    "    \"N_PIXELS\": 128,\n",
    "    \"PIXEL_SIZE\": 2.08,\n",
    "    \"SIGMA\": 4.0,\n",
    "    \"ROTATIONS\": True,\n",
    "    \"SHIFT\": False,\n",
    "    \"CTF\": True,\n",
    "    \"NOISE\": True,\n",
    "    \"DEFOCUS\": 2.0,\n",
    "    \"SNR\": 0.15,\n",
    "    \"RADIUS_MASK\": 64,\n",
    "    \"AMP\": 0.1,\n",
    "    \"B_FACTOR\": 1,\n",
    "    \"ELECWAVE\": 0.019866,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446f993-3ba3-44c7-a281-13f0e6b96153",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = np.load(\"../data/protein_models/6wxb_torsion_models.npy\")[model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3653c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift = np.random.uniform(-80, 80, size=(2, 1))\n",
    "# coord[:2, :] += shift"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f29d467-2b4e-4d54-8585-62cf707696f0",
   "metadata": {},
   "source": [
    "## Rotate structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb7e3a-67e4-4b47-a752-eb0242b54d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quat = np.array([-0.76882173,  0.21902341, -0.3074588 ,  0.51615015])\n",
    "# quat = np.array([-0.10225028, 0.72071227, -0.62394053, -0.28428316])\n",
    "quat = gen_quat()\n",
    "rot_mat = Rotation.from_quat(quat).as_matrix()\n",
    "coord = np.matmul(rot_mat, coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# ax.plot_surface(\n",
    "#    x, y, z,  rstride=1, cstride=1, color='c', alpha=0.3, linewidth=0)\n",
    "xx, yy, zz = coord\n",
    "im = ax.scatter(xx, yy, zz, s=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43c59c04-9d95-4033-b423-92674866e1cd",
   "metadata": {},
   "source": [
    "## Generating the projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e397a04-d95c-4f9f-8a03-f5968f7ddd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_img(coord, image_params):\n",
    "    n_atoms = coord.shape[1]\n",
    "    norm = 1 / (2 * torch.pi * image_params[\"SIGMA\"] ** 2 * n_atoms)\n",
    "\n",
    "    grid_min = -image_params[\"PIXEL_SIZE\"] * (image_params[\"N_PIXELS\"] - 1) * 0.5\n",
    "    grid_max = (\n",
    "        image_params[\"PIXEL_SIZE\"] * (image_params[\"N_PIXELS\"] - 1) * 0.5\n",
    "        + image_params[\"PIXEL_SIZE\"]\n",
    "    )\n",
    "\n",
    "    grid = torch.arange(grid_min, grid_max, image_params[\"PIXEL_SIZE\"])\n",
    "\n",
    "    gauss_x = torch.exp(\n",
    "        -0.5 * (((grid[:, None] - coord[0, :]) / image_params[\"SIGMA\"]) ** 2)\n",
    "    )\n",
    "\n",
    "    gauss_y = torch.exp(\n",
    "        -0.5 * (((grid[:, None] - coord[1, :]) / image_params[\"SIGMA\"]) ** 2)\n",
    "    )\n",
    "\n",
    "    image = torch.matmul(gauss_x, gauss_y.T) * norm\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfa477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_mask(n_pixels, radius, x_center=None, y_center=None):\n",
    "    \"\"\"Creates a circular mask of radius RADIUS_MASK centered in the image.\n",
    "\n",
    "    Args:\n",
    "        n_pixels (int): Number of pixels along image side.\n",
    "        radius (int): Radius of the mask.\n",
    "        x_center (int): X-coordinate of the center of the circle.\n",
    "        y_center (int): Y-coordinate of the center of the circle.\n",
    "\n",
    "    Returns:\n",
    "        mask (torch.Tensor): Mask of shape (n_pixels, n_pixels).\n",
    "    \"\"\"\n",
    "\n",
    "    if x_center is None:\n",
    "        x_center = (n_pixels - 1) / 2  # Default center\n",
    "    if y_center is None:\n",
    "        y_center = (n_pixels - 1) / 2  # Default center\n",
    "\n",
    "    x = torch.linspace(0, n_pixels - 1, n_pixels)\n",
    "    y = torch.linspace(0, n_pixels - 1, n_pixels)\n",
    "    x_2d, y_2d = torch.meshgrid(x, y)\n",
    "    r_2d = (x_2d - x_center) ** 2 + (y_2d - y_center) ** 2\n",
    "    mask = r_2d < radius**2\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = circular_mask(\n",
    "    image_params[\"N_PIXELS\"], 100, x_center=64 + shift[0][0], y_center=64 + shift[1][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770414e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_clear = gen_img(coord, image_params)\n",
    "print(image_clear.shape)\n",
    "plt.imshow(image_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb22c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_clear + mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8ef0ab1-f72d-4289-bfd9-10b4979e7c17",
   "metadata": {},
   "source": [
    "## Add padding for shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa51c03-d5b1-44e7-be52-a680fc7516ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ConstantPad2d\n",
    "\n",
    "\n",
    "def pad_image(image, image_params):\n",
    "    pad_width = int(np.ceil(image_params[\"N_PIXELS\"] * 0.1)) + 1\n",
    "\n",
    "    padder = ConstantPad2d(pad_width, 0.0)\n",
    "\n",
    "    padded_image = padder(image)\n",
    "\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a94929-2872-4a9a-bfe5-093de5345d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_clear = pad_image(image_clear, image_params)\n",
    "plt.imshow(image_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise_field(num_pixels, num_sin_func=10, max_intensity=1e-3):\n",
    "    \"\"\"Generate a noise field with a given number of sinusoidal functions.\n",
    "\n",
    "    Args:\n",
    "        num_pixels (int): Number of pixels in the noise field.\n",
    "        num_sin_func (int, optional): Number of sinusoidal functions. Defaults to 10.\n",
    "        max_intensity (float, optional): Maximum intensity of the noise field. Defaults to 1e-3.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Noise field.\n",
    "    \"\"\"\n",
    "\n",
    "    x = torch.linspace(-100, 100, num_pixels)\n",
    "    y = torch.linspace(-100, 100, num_pixels)\n",
    "    xx, yy = torch.meshgrid(x, y)\n",
    "\n",
    "    a = 1 * (torch.rand((num_sin_func))) + 1\n",
    "    b = torch.rand(1) * (torch.rand((num_sin_func, 2)) - 0.5)\n",
    "    c = 2 * np.pi * (torch.rand(num_sin_func, 2) - 0.5)\n",
    "\n",
    "    noise_field = torch.zeros_like(xx, dtype=torch.double)\n",
    "    for i in range(num_sin_func):\n",
    "        noise_field += (\n",
    "            a[i] * torch.sin(b[i, 0] * xx + c[i, 0]) * torch.sin(b[i, 1] * yy + c[i, 1])\n",
    "        )\n",
    "    noise_field = max_intensity * (noise_field / noise_field.max())\n",
    "    return noise_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a854ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gen_noise_field(image_clear.shape[0], num_sin_func=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858404ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = image_clear < 1e-12\n",
    "# image_clear[idx] = gen_noise_field(\n",
    "#    image_clear.shape[0], num_sin_func=80, max_intensity=image_clear.max() * 0.6\n",
    "# )[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51550a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_clear)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c98392e-4cfd-4d88-98e8-01230b632a71",
   "metadata": {},
   "source": [
    "## Calculate and add the ctf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38846bfb-d8f0-4d50-bd91-decc3ecfe1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ctf(image_params):\n",
    "    # Attention look into def pad_image function to know the image size after padding\n",
    "    image_size = (\n",
    "        # 2 * (int(np.ceil(image_params[\"N_PIXELS\"] * 0.1)) + 1)\n",
    "        image_params[\"N_PIXELS\"]\n",
    "    )\n",
    "    freq_pix_1d = torch.fft.fftfreq(image_size, d=image_params[\"PIXEL_SIZE\"])\n",
    "\n",
    "    if isinstance(image_params[\"DEFOCUS\"], float):\n",
    "        phase = image_params[\"DEFOCUS\"] * np.pi * 2.0 * 10000 * image_params[\"ELECWAVE\"]\n",
    "\n",
    "    elif (\n",
    "        isinstance(image_params[\"DEFOCUS\"], list) and len(image_params[\"DEFOCUS\"]) == 2\n",
    "    ):\n",
    "        defocus = np.random.uniform(\n",
    "            low=image_params[\"DEFOCUS\"][0], high=image_params[\"DEFOCUS\"][1]\n",
    "        )\n",
    "        phase = defocus * np.pi * 2.0 * 10000 * image_params[\"ELECWAVE\"]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Defocus should be a single value or a list of [min_defocus, max_defocus]\"\n",
    "        )\n",
    "\n",
    "    x, y = torch.meshgrid(freq_pix_1d, freq_pix_1d)\n",
    "\n",
    "    freq2_2d = x**2 + y**2\n",
    "    imag = torch.zeros_like(freq2_2d) * 1j\n",
    "\n",
    "    env = torch.exp(torch.tensor(-image_params[\"B_FACTOR\"] * freq2_2d * 0.5))\n",
    "    ctf = (\n",
    "        -image_params[\"AMP\"] * torch.tensor(phase * freq2_2d * 0.5).cos()\n",
    "        - torch.tensor(1 - image_params[\"AMP\"] ** 2).sqrt()\n",
    "        * torch.tensor(phase * freq2_2d * 0.5).sin()\n",
    "        + imag\n",
    "    )\n",
    "    return ctf * env / image_params[\"AMP\"]\n",
    "\n",
    "\n",
    "def circular_mask1(n_pixels, radius, inside=True):\n",
    "    grid = torch.linspace(-0.5 * (n_pixels - 1), 0.5 * (n_pixels - 1), n_pixels)\n",
    "    r_2d = grid[None, :] ** 2 + grid[:, None] ** 2\n",
    "\n",
    "    if inside is True:\n",
    "        mask = r_2d < radius**2\n",
    "    else:\n",
    "        mask = r_2d > radius**2\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def apply_ctf(image, ctf):\n",
    "    conv_image_ctf = torch.fft.fft2(image) * ctf\n",
    "    image_ctf = torch.fft.ifft2(conv_image_ctf).real\n",
    "\n",
    "    return image_ctf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b567a511-b492-45b7-82cc-6a559d0b61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctf = calc_ctf(image_params)\n",
    "image_ctf = apply_ctf(image_clear, ctf)\n",
    "plt.imshow(image_ctf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_ctf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91273520",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((torch.fft.ifftshift(ctf)).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88019d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((torch.fft.ifftshift(ctf)).abs())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b124af6e-4dfd-415c-a346-2831e8862e2b",
   "metadata": {},
   "source": [
    "## Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3f4ed-58a4-4a50-ac8f-bb654ef4f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_mask(n_pixels, radius):\n",
    "    grid = torch.linspace(-0.5 * (n_pixels - 1), 0.5 * (n_pixels - 1), n_pixels)\n",
    "    r_2d = grid[None, :] ** 2 + grid[:, None] ** 2\n",
    "    mask = r_2d < radius**2\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def add_noise(img, image_params):\n",
    "    mask = circular_mask(n_pixels=img.shape[0], radius=image_params[\"RADIUS_MASK\"])\n",
    "\n",
    "    signal_std = img[mask].pow(2).mean().sqrt()\n",
    "\n",
    "    if isinstance(image_params[\"SNR\"], float):\n",
    "        snr = image_params[\"SNR\"]\n",
    "\n",
    "    elif isinstance(image_params[\"SNR\"], list) and len(image_params[\"SNR\"]) == 2:\n",
    "        snr = np.random.uniform(low=image_params[\"SNR\"][0], high=image_params[\"SNR\"][1])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"SNR should be a single value or a list of [min_defocus, max_defocus]\"\n",
    "        )\n",
    "\n",
    "    noise_std = signal_std / np.sqrt(snr)\n",
    "\n",
    "    img_noise = img + torch.distributions.normal.Normal(0, noise_std).sample(img.shape)\n",
    "\n",
    "    return img_noise\n",
    "\n",
    "\n",
    "def add_gradient_noise(img, image_params):\n",
    "    mask = circular_mask(n_pixels=img.shape[0], radius=image_params[\"RADIUS_MASK\"])\n",
    "\n",
    "    signal_std = img[mask].pow(2).mean().sqrt()\n",
    "    noise_std = signal_std / np.sqrt(image_params[\"SNR\"])\n",
    "\n",
    "    noise = torch.stack(\n",
    "        [\n",
    "            torch.distributions.normal.Normal(0, signal_std / np.sqrt(snr)).sample(\n",
    "                [\n",
    "                    img.shape[0],\n",
    "                ]\n",
    "            )\n",
    "            for snr in np.logspace(-1, -2, img.shape[0])\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "\n",
    "    img_noise = img + noise\n",
    "\n",
    "    return img_noise\n",
    "\n",
    "\n",
    "def add_shot_noise(clear_image, image_params):\n",
    "    norm_img = clear_image.abs() / clear_image.abs().max()\n",
    "    shot_noise = torch.poisson(norm_img * 0.05)\n",
    "\n",
    "    shot_image = clear_image * (shot_noise + 1)\n",
    "    print(shot_noise.sum())\n",
    "    ctf_image = apply_ctf(shot_image, calc_ctf(image_params))\n",
    "\n",
    "    img = add_noise(ctf_image, image_params)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def add_colored_noise(image, image_params, seed, noise_intensity=1, noise_scale=1.5):\n",
    "    \"\"\"Adds colored noise to image\"\"\"\n",
    "    # Similar to pink noise https://en.wikipedia.org/wiki/Pink_noise\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    print(image.shape, \"1\")\n",
    "    image_L = image.shape[0]\n",
    "\n",
    "    mask = circular_mask(n_pixels=image.shape[0], radius=image_params[\"RADIUS_MASK\"])\n",
    "\n",
    "    signal_std = image[mask].pow(2).mean().sqrt()\n",
    "    noise_std = signal_std / np.sqrt(image_params[\"SNR\"])\n",
    "\n",
    "    image_noise = torch.distributions.normal.Normal(0, noise_std).sample(image.shape)\n",
    "    fft_noise = torch.fft.fft2(image_noise)\n",
    "\n",
    "    along_x, along_y = np.linspace(-1, 1, image_L), np.linspace(-1, 1, image_L)\n",
    "    mesh_x, mesh_y = np.meshgrid(along_x, along_y)\n",
    "    f = torch.zeros((image_L, image_L))\n",
    "\n",
    "    for ix in range(image_L):\n",
    "        for iy in range(image_L):\n",
    "            f[ix, iy] = (\n",
    "                np.abs(mesh_x[ix, iy]) ** noise_scale\n",
    "                + np.abs(mesh_y[ix, iy]) ** noise_scale\n",
    "            )\n",
    "    print(fft_noise.shape, \"2\")\n",
    "    t = torch.abs(torch.fft.ifft2(fft_noise / f))\n",
    "\n",
    "    # Scaling with respect to the lenght max to median\n",
    "    scale = noise_intensity / (t.max() - t.median())\n",
    "\n",
    "    # Adjusting noise so that 50% of the pixels have higer and the other 50% lower snr\n",
    "    t = ((t - t.median()) * scale) + 1\n",
    "\n",
    "    image_noise = torch.distributions.normal.Normal(0, noise_std * t).sample()\n",
    "    return image_noise + image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5b9c3-bc7c-414e-b305-0e869c3a99bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = add_noise(image_ctf, image_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25738586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = add_colored_noise(image_ctf, image_params, seed=None, noise_intensity=1, noise_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efb7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = add_shot_noise(image, image_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(add_colored_noise(image, image_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7648f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_shot_noise(image, image_params).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aaa233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(add_shot_noise(image_clear, image_params))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da889ed7-58b9-4031-b057-27e29de60500",
   "metadata": {},
   "source": [
    "## Add random shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d4d0f9-12c4-4dc2-b48d-e181b76d5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_shift(padded_image, image_params):\n",
    "    shift_x = int(torch.ceil(image_params[\"N_PIXELS\"] * 0.1 * (2 * torch.rand(1) - 1)))\n",
    "    shift_y = int(torch.ceil(image_params[\"N_PIXELS\"] * 0.1 * (2 * torch.rand(1) - 1)))\n",
    "\n",
    "    pad_width = int(np.ceil(image_params[\"N_PIXELS\"] * 0.1)) + 1\n",
    "\n",
    "    low_ind_x = pad_width - shift_x\n",
    "    high_ind_x = padded_image.shape[0] - pad_width - shift_x\n",
    "\n",
    "    low_ind_y = pad_width - shift_y\n",
    "    high_ind_y = padded_image.shape[0] - pad_width - shift_y\n",
    "\n",
    "    shifted_image = padded_image[low_ind_x:high_ind_x, low_ind_y:high_ind_y]\n",
    "\n",
    "    return shifted_image\n",
    "\n",
    "\n",
    "def apply_no_shift(padded_image, image_params):\n",
    "    pad_width = int(np.ceil(image_params[\"N_PIXELS\"] * 0.1)) + 1\n",
    "\n",
    "    low_ind_x = pad_width\n",
    "    high_ind_x = padded_image.shape[0] - pad_width\n",
    "\n",
    "    low_ind_y = pad_width\n",
    "    high_ind_y = padded_image.shape[0] - pad_width\n",
    "\n",
    "    shifted_image = padded_image[low_ind_x:high_ind_x, low_ind_y:high_ind_y]\n",
    "\n",
    "    return shifted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57391707-34f8-4dfa-a2fd-268121b1f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = apply_no_shift(image, image_params)\n",
    "# plt.imshow(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ae58b27-28f8-4a87-af1a-eda2b7cc776f",
   "metadata": {},
   "source": [
    "## Normalize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c3896-19b3-44be-a2b7-107982e2ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_normalize_image(image):\n",
    "    mean_img = torch.mean(image)\n",
    "    std_img = torch.std(image)\n",
    "\n",
    "    return (image - mean_img) / std_img\n",
    "\n",
    "\n",
    "image = gaussian_normalize_image(image).to(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c475e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image, vmax=4, vmin=-4, cmap=\"binary\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryo_sbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1391d301e9aa4dc24331c4a52095d8473e5107d84c03241f78234deb9fd2437e"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
