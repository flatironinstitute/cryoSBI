{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de16e975-19a1-47b9-aa77-0ec77b576c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cryo_sbi.wpa_simulator.image_generation import gen_quat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c6bc3-879f-4863-81fd-a4d955f39d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_idx = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c54ae-e51a-4de4-a1f7-eab51cd91a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_params = {\n",
    "                'N_PIXELS': 128,\n",
    "                'PIXEL_SIZE': 2.08,\n",
    "                'SIGMA': 4.0,\n",
    "                'ROTATIONS': True,\n",
    "                'SHIFT': True,\n",
    "                'CTF': True,\n",
    "                'NOISE': True,\n",
    "                'DEFOCUS': 1.0,\n",
    "                'SNR': 0.1,\n",
    "                'RADIUS_MASK': 64,\n",
    "                'AMP': 0.1,\n",
    "                'B_FACTOR': 1,\n",
    "                'ELECWAVE': 0.019866\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446f993-3ba3-44c7-a281-13f0e6b96153",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = np.load(\"../data/protein_models/6wxb_models.npy\")[model_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f29d467-2b4e-4d54-8585-62cf707696f0",
   "metadata": {},
   "source": [
    "## Rotate structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb7e3a-67e4-4b47-a752-eb0242b54d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "quat = np.array([-0.76882173,  0.21902341, -0.3074588 ,  0.51615015])\n",
    "rot_mat = Rotation.from_quat(quat).as_matrix()\n",
    "coord = np.matmul(rot_mat, coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c59c04-9d95-4033-b423-92674866e1cd",
   "metadata": {},
   "source": [
    "## Generating the projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e397a04-d95c-4f9f-8a03-f5968f7ddd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_img(coord, image_params):\n",
    "\n",
    "    n_atoms = coord.shape[1]\n",
    "    norm = 1 / (2 * torch.pi * image_params[\"SIGMA\"] ** 2 * n_atoms)\n",
    "\n",
    "    grid_min = -image_params[\"PIXEL_SIZE\"] * (image_params[\"N_PIXELS\"]  - 1) * 0.5\n",
    "    grid_max = (\n",
    "        image_params[\"PIXEL_SIZE\"] * (image_params[\"N_PIXELS\"] - 1) * 0.5\n",
    "        + image_params[\"PIXEL_SIZE\"]\n",
    "    )\n",
    "\n",
    "    grid = torch.arange(grid_min, grid_max, image_params[\"PIXEL_SIZE\"])\n",
    "\n",
    "    gauss_x = torch.exp(\n",
    "        -0.5 * (((grid[:, None] - coord[0, :]) / image_params[\"SIGMA\"]) ** 2)\n",
    "    )\n",
    "\n",
    "    gauss_y = torch.exp(\n",
    "        -0.5 * (((grid[:, None] - coord[1, :]) / image_params[\"SIGMA\"]) ** 2)\n",
    "    )\n",
    "\n",
    "    image = torch.matmul(gauss_x, gauss_y.T) * norm\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770414e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_clear = gen_img(coord, image_params)\n",
    "print(image_clear.shape)\n",
    "plt.imshow(image_clear)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8ef0ab1-f72d-4289-bfd9-10b4979e7c17",
   "metadata": {},
   "source": [
    "## Add padding for shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa51c03-d5b1-44e7-be52-a680fc7516ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ConstantPad2d\n",
    "def pad_image(image, image_params):\n",
    "\n",
    "    pad_width = int(np.ceil(image_params[\"N_PIXELS\"] * 0.1)) + 1\n",
    "    \n",
    "    padder = ConstantPad2d(pad_width, 0.0)\n",
    "\n",
    "    padded_image = padder(image)\n",
    "\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a94929-2872-4a9a-bfe5-093de5345d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_clear = pad_image(image_clear, image_params)\n",
    "plt.imshow(image_clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c98392e-4cfd-4d88-98e8-01230b632a71",
   "metadata": {},
   "source": [
    "## Calculate and add the ctf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38846bfb-d8f0-4d50-bd91-decc3ecfe1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ctf(image_params):\n",
    "\n",
    "    # Attention look into def pad_image function to know the image size after padding \n",
    "    image_size = 2 * ( int(np.ceil(image_params[\"N_PIXELS\"] * 0.1)) + 1) + image_params[\"N_PIXELS\"]\n",
    "    freq_pix_1d = torch.fft.fftfreq(\n",
    "        image_size,\n",
    "        d=image_params[\"PIXEL_SIZE\"]\n",
    "    )\n",
    "\n",
    "    if isinstance(image_params[\"DEFOCUS\"], float):\n",
    "        phase = image_params[\"DEFOCUS\"] * np.pi * 2.0 * 10000 * image_params[\"ELECWAVE\"]\n",
    "\n",
    "    elif isinstance(image_params[\"DEFOCUS\"], list) and len(image_params[\"DEFOCUS\"]) == 2:\n",
    "        defocus = np.random.uniform(low=image_params[\"DEFOCUS\"][0], high=image_params[\"DEFOCUS\"][1])\n",
    "        phase = defocus * np.pi * 2.0 * 10000 * image_params[\"ELECWAVE\"]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Defocus should be a single value or a list of [min_defocus, max_defocus]\")\n",
    "\n",
    "    x, y = torch.meshgrid(freq_pix_1d, freq_pix_1d)\n",
    "\n",
    "    freq2_2d = x**2 + y**2\n",
    "    imag = torch.zeros_like(freq2_2d) * 1j\n",
    "\n",
    "    env = torch.exp(torch.tensor(-image_params[\"B_FACTOR\"] * freq2_2d * 0.5))\n",
    "    ctf = (\n",
    "        image_params[\"AMP\"] * torch.tensor(phase * freq2_2d * 0.5).cos()\n",
    "        - torch.tensor(1 - image_params[\"AMP\"]**2).sqrt()\n",
    "        * torch.tensor(phase * freq2_2d * 0.5).sin()\n",
    "        + imag\n",
    "    )\n",
    "    return ctf * env / image_params[\"AMP\"]\n",
    "\n",
    "\n",
    "def apply_ctf(image, ctf):\n",
    "\n",
    "    conv_image_ctf = torch.fft.fft2(image) * ctf.real\n",
    "\n",
    "    image_ctf = torch.fft.ifft2(conv_image_ctf).real\n",
    "\n",
    "    return image_ctf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b567a511-b492-45b7-82cc-6a559d0b61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctf = calc_ctf(image_params)\n",
    "image_ctf = apply_ctf(image_clear, calc_ctf(image_params))\n",
    "plt.imshow(image_ctf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91273520",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ctf.real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124af6e-4dfd-415c-a346-2831e8862e2b",
   "metadata": {},
   "source": [
    "## Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3f4ed-58a4-4a50-ac8f-bb654ef4f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_mask(n_pixels, radius):\n",
    "\n",
    "    grid = torch.linspace(-0.5 * (n_pixels - 1), 0.5 * (n_pixels - 1), n_pixels)\n",
    "    r_2d = grid[None, :]**2 + grid[:, None]**2\n",
    "    mask = r_2d < radius**2\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def add_noise(img, image_params):\n",
    "\n",
    "    mask = circular_mask(n_pixels=img.shape[0], radius=image_params[\"RADIUS_MASK\"])\n",
    "\n",
    "    signal_std = img[mask].pow(2).mean().sqrt()\n",
    "\n",
    "    if isinstance(image_params[\"SNR\"], float):\n",
    "        snr = image_params[\"SNR\"]\n",
    "\n",
    "    elif isinstance(image_params[\"SNR\"], list) and len(image_params[\"SNR\"]) == 2:\n",
    "        snr = np.random.uniform(low=image_params[\"SNR\"][0], high=image_params[\"SNR\"][1])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"SNR should be a single value or a list of [min_defocus, max_defocus]\")\n",
    "\n",
    "    noise_std = signal_std / np.sqrt(snr)\n",
    "\n",
    "    img_noise = img + torch.distributions.normal.Normal(0, noise_std).sample(img.shape)\n",
    "\n",
    "    return img_noise\n",
    "\n",
    "\n",
    "def add_gradient_noise(img, image_params):\n",
    "\n",
    "    mask = circular_mask(n_pixels=img.shape[0], radius=image_params[\"RADIUS_MASK\"])\n",
    "\n",
    "    signal_std = img[mask].pow(2).mean().sqrt()\n",
    "    noise_std = signal_std / np.sqrt(image_params[\"SNR\"])\n",
    "    \n",
    "    noise = torch.stack(\n",
    "        [\n",
    "            torch.distributions.normal.Normal(0, signal_std / np.sqrt(snr)).sample([img.shape[0],]) \n",
    "            for snr in np.logspace(-1, -2, img.shape[0])\n",
    "        ],\n",
    "        dim=1\n",
    "    )\n",
    "    \n",
    "    img_noise = img + noise\n",
    "\n",
    "    return img_noise\n",
    "\n",
    "\n",
    "def add_shot_noise(clear_image, image_params):\n",
    "\n",
    "    norm_img = clear_image.abs() / clear_image.abs().max()\n",
    "    shot_noise = torch.poisson(norm_img * 0.05)\n",
    "    \n",
    "    shot_image = clear_image * (shot_noise + 1)\n",
    "    print(shot_noise.sum())\n",
    "    ctf_image = apply_ctf(shot_image, calc_ctf(image_params))\n",
    "\n",
    "    img = add_noise(ctf_image, image_params)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def add_colored_noise(image, image_params, seed, noise_intensity=1, noise_scale=1.5):\n",
    "    \"\"\"Adds colored noise to image\"\"\"\n",
    "    # Similar to pink noise https://en.wikipedia.org/wiki/Pink_noise\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    print(image.shape, '1')\n",
    "    image_L = image.shape[0]\n",
    "\n",
    "    mask = circular_mask(n_pixels=image.shape[0], radius=image_params[\"RADIUS_MASK\"])\n",
    "\n",
    "    signal_std = image[mask].pow(2).mean().sqrt()\n",
    "    noise_std = signal_std / np.sqrt(image_params[\"SNR\"])\n",
    "\n",
    "    image_noise = torch.distributions.normal.Normal(0, noise_std).sample(image.shape)\n",
    "    fft_noise = torch.fft.fft2(image_noise)\n",
    "\n",
    "    along_x, along_y = np.linspace(-1, 1, image_L), np.linspace(-1, 1, image_L)\n",
    "    mesh_x, mesh_y = np.meshgrid(along_x, along_y)\n",
    "    f = torch.zeros((image_L, image_L))\n",
    "\n",
    "    for ix in range(image_L):\n",
    "        for iy in range(image_L):\n",
    "            f[ix, iy] = (\n",
    "                np.abs(mesh_x[ix, iy]) ** noise_scale\n",
    "                + np.abs(mesh_y[ix, iy]) ** noise_scale\n",
    "            )\n",
    "    print(fft_noise.shape, '2')\n",
    "    t = torch.abs(torch.fft.ifft2(fft_noise / f))\n",
    "\n",
    "    # Scaling with respect to the lenght max to median\n",
    "    scale = noise_intensity / (t.max() - t.median())\n",
    "\n",
    "    # Adjusting noise so that 50% of the pixels have higer and the other 50% lower snr\n",
    "    t = ((t - t.median()) * scale) + 1\n",
    "\n",
    "    image_noise = torch.distributions.normal.Normal(0, noise_std * t).sample()\n",
    "    return image_noise + image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5b9c3-bc7c-414e-b305-0e869c3a99bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = add_noise(image_ctf, image_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25738586",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = add_colored_noise(image_ctf, image_params, seed=None, noise_intensity=1, noise_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efb7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = add_shot_noise(image, image_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(add_colored_noise(image, image_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7648f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_shot_noise(image, image_params).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aaa233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(add_shot_noise(image_clear, image_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da889ed7-58b9-4031-b057-27e29de60500",
   "metadata": {},
   "source": [
    "## Add random shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d4d0f9-12c4-4dc2-b48d-e181b76d5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_shift(padded_image, image_params):\n",
    "\n",
    "    shift_x = int(torch.ceil(image_params[\"N_PIXELS\"] * 0.1 * (2 * torch.rand(1) - 1)))\n",
    "    shift_y = int(torch.ceil(image_params[\"N_PIXELS\"] * 0.1 * (2 * torch.rand(1) - 1)))\n",
    "\n",
    "    pad_width = int(np.ceil(image_params[\"N_PIXELS\"] * 0.1)) + 1\n",
    "\n",
    "    low_ind_x = pad_width - shift_x\n",
    "    high_ind_x = padded_image.shape[0] - pad_width - shift_x\n",
    "\n",
    "    low_ind_y = pad_width - shift_y\n",
    "    high_ind_y = padded_image.shape[0] - pad_width - shift_y\n",
    "\n",
    "    shifted_image = padded_image[low_ind_x:high_ind_x, low_ind_y:high_ind_y]\n",
    "\n",
    "    return shifted_image\n",
    "\n",
    "\n",
    "def apply_no_shift(padded_image, image_params):\n",
    "\n",
    "    pad_width = int(np.ceil(image_params[\"N_PIXELS\"] * 0.1)) + 1\n",
    "\n",
    "    low_ind_x = pad_width\n",
    "    high_ind_x = padded_image.shape[0] - pad_width\n",
    "\n",
    "    low_ind_y = pad_width\n",
    "    high_ind_y = padded_image.shape[0] - pad_width\n",
    "\n",
    "    shifted_image = padded_image[low_ind_x:high_ind_x, low_ind_y:high_ind_y]\n",
    "\n",
    "    return shifted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57391707-34f8-4dfa-a2fd-268121b1f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = apply_random_shift(image, image_params)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae58b27-28f8-4a87-af1a-eda2b7cc776f",
   "metadata": {},
   "source": [
    "## Normalize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c3896-19b3-44be-a2b7-107982e2ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_normalize_image(image):\n",
    "\n",
    "    mean_img = torch.mean(image)\n",
    "    std_img = torch.std(image)\n",
    "\n",
    "    return (image - mean_img) / std_img\n",
    "\n",
    "image = gaussian_normalize_image(image).to(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00194f00-8563-450f-ad18-0221e5872c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image, vmax=4, vmin=-4, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef4653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryo_sbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1391d301e9aa4dc24331c4a52095d8473e5107d84c03241f78234deb9fd2437e"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
