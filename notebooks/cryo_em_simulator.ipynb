{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de16e975-19a1-47b9-aa77-0ec77b576c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cryo_sbi.wpa_simulator.image_generation import gen_quat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c6bc3-879f-4863-81fd-a4d955f39d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_idx = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c54ae-e51a-4de4-a1f7-eab51cd91a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_params = {\n",
    "                'N_PIXELS': 128,\n",
    "                'PIXEL_SIZE': 1.5,\n",
    "                'SIGMA': 4.0,\n",
    "                'ROTATIONS': True,\n",
    "                'SHIFT': True,\n",
    "                'CTF': True,\n",
    "                'NOISE': True,\n",
    "                'DEFOCUS': 1.5,\n",
    "                'SNR': 0.1,\n",
    "                'RADIUS_MASK': 64,\n",
    "                'AMP': 0.1,\n",
    "                'B_FACTOR': 1,\n",
    "                'ELECWAVE': 0.019866\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446f993-3ba3-44c7-a281-13f0e6b96153",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = np.load(\"../data/protein_models/hsp90_models.npy\")[model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404bd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = []\n",
    "centers = []\n",
    "for i in range(3):\n",
    "    coord = np.load(\"../data/protein_models/hsp90_models.npy\")[:, 0][10]\n",
    "    rot_mat = Rotation.from_quat(gen_quat()).as_matrix()\n",
    "    coord = np.matmul(rot_mat, coord)\n",
    "\n",
    "    if i > 0:\n",
    "        r = np.random.uniform(low=50, high=180)\n",
    "        phi = np.random.uniform(low=0, high=2*np.pi)\n",
    "        coord += np.array([r*np.cos(phi), r*np.sin(phi), 0]).reshape(-1, 1)\n",
    "        centers.append((r*np.cos(phi), r*np.sin(phi)))\n",
    "    \n",
    "    coords.append(coord)\n",
    "coord = np.concatenate(coords, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f29d467-2b4e-4d54-8585-62cf707696f0",
   "metadata": {},
   "source": [
    "## Rotate structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb7e3a-67e4-4b47-a752-eb0242b54d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quat = np.array([-0.76882173,  0.21902341, -0.3074588 ,  0.51615015])\n",
    "#rot_mat = Rotation.from_quat(quat).as_matrix()\n",
    "#coord = np.matmul(rot_mat, coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c59c04-9d95-4033-b423-92674866e1cd",
   "metadata": {},
   "source": [
    "## Generating the projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e397a04-d95c-4f9f-8a03-f5968f7ddd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_ratio = 1\n",
    "def gen_img(coord, image_params):\n",
    "\n",
    "    n_atoms = coord.shape[1]\n",
    "    norm = 1 / (2 * torch.pi * image_params[\"SIGMA\"] ** 2 * n_atoms)\n",
    "\n",
    "    extra_pixel = round(image_params[\"N_PIXELS\"] * margin_ratio)\n",
    "    grid_min = -image_params[\"PIXEL_SIZE\"] * (image_params[\"N_PIXELS\"] + extra_pixel - 1) * 0.5\n",
    "    grid_max = (\n",
    "        image_params[\"PIXEL_SIZE\"] * (image_params[\"N_PIXELS\"] + extra_pixel - 1) * 0.5\n",
    "        + image_params[\"PIXEL_SIZE\"]\n",
    "    )\n",
    "\n",
    "    grid = torch.arange(grid_min, grid_max, image_params[\"PIXEL_SIZE\"])\n",
    "\n",
    "    gauss_x = torch.exp(\n",
    "        -0.5 * (((grid[:, None] - coord[0, :]) / image_params[\"SIGMA\"]) ** 2)\n",
    "    )\n",
    "\n",
    "    gauss_y = torch.exp(\n",
    "        -0.5 * (((grid[:, None] - coord[1, :]) / image_params[\"SIGMA\"]) ** 2)\n",
    "    )\n",
    "\n",
    "    image = torch.matmul(gauss_x, gauss_y.T) * norm\n",
    "\n",
    "    return image, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770414e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_clear, grid = gen_img(coord, image_params)\n",
    "print(image_clear.shape)\n",
    "plt.imshow(image_clear)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8ef0ab1-f72d-4289-bfd9-10b4979e7c17",
   "metadata": {},
   "source": [
    "## Add padding for shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa51c03-d5b1-44e7-be52-a680fc7516ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ConstantPad2d\n",
    "def pad_image(image, image_params):\n",
    "\n",
    "    pad_width = int(np.ceil(image_params[\"N_PIXELS\"] * 0.1)) + 1\n",
    "    \n",
    "    padder = ConstantPad2d(pad_width, 0.0)\n",
    "\n",
    "    padded_image = padder(image)\n",
    "\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c98392e-4cfd-4d88-98e8-01230b632a71",
   "metadata": {},
   "source": [
    "## Calculate and add the ctf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38846bfb-d8f0-4d50-bd91-decc3ecfe1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ctf(image_params):\n",
    "\n",
    "    # Attention look into def pad_image function to know the image size after padding \n",
    "    extra_pixel = round(image_params[\"N_PIXELS\"] * margin_ratio) #2 * ( int(np.ceil(image_params[\"N_PIXELS\"] * 0.1)) + 1) + image_params[\"N_PIXELS\"]\n",
    "    image_size = image_params[\"N_PIXELS\"] + extra_pixel\n",
    "    freq_pix_1d = torch.fft.fftfreq(\n",
    "        image_size,\n",
    "        d=image_params[\"PIXEL_SIZE\"]\n",
    "    )\n",
    "\n",
    "    if isinstance(image_params[\"DEFOCUS\"], float):\n",
    "        phase = image_params[\"DEFOCUS\"] * np.pi * 2.0 * 10000 * image_params[\"ELECWAVE\"]\n",
    "\n",
    "    elif isinstance(image_params[\"DEFOCUS\"], list) and len(image_params[\"DEFOCUS\"]) == 2:\n",
    "        defocus = np.random.uniform(low=image_params[\"DEFOCUS\"][0], high=image_params[\"DEFOCUS\"][1])\n",
    "        phase = defocus * np.pi * 2.0 * 10000 * image_params[\"ELECWAVE\"]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Defocus should be a single value or a list of [min_defocus, max_defocus]\")\n",
    "\n",
    "    x, y = torch.meshgrid(freq_pix_1d, freq_pix_1d)\n",
    "\n",
    "    freq2_2d = x**2 + y**2\n",
    "    imag = torch.zeros_like(freq2_2d) * 1j\n",
    "\n",
    "    env = torch.exp(torch.tensor(-image_params[\"B_FACTOR\"] * freq2_2d * 0.5))\n",
    "    ctf = (\n",
    "        image_params[\"AMP\"] * torch.tensor(phase * freq2_2d * 0.5).cos()\n",
    "        - torch.tensor(1 - image_params[\"AMP\"]**2).sqrt()\n",
    "        * torch.tensor(phase * freq2_2d * 0.5).sin()\n",
    "        + imag\n",
    "    )\n",
    "    return ctf * env / image_params[\"AMP\"]\n",
    "\n",
    "\n",
    "def apply_ctf(image, ctf):\n",
    "\n",
    "    conv_image_ctf = torch.fft.fft2(image) * ctf.real\n",
    "\n",
    "    image_ctf = torch.fft.ifft2(conv_image_ctf).real\n",
    "\n",
    "    return image_ctf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b567a511-b492-45b7-82cc-6a559d0b61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctf = calc_ctf(image_params)\n",
    "image_ctf = apply_ctf(image_clear, calc_ctf(image_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_ctf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91273520",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ctf.real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124af6e-4dfd-415c-a346-2831e8862e2b",
   "metadata": {},
   "source": [
    "## Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3f4ed-58a4-4a50-ac8f-bb654ef4f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_mask(n_pixels, radius):\n",
    "\n",
    "    grid = torch.linspace(-0.5 * (n_pixels - 1), 0.5 * (n_pixels - 1), n_pixels)\n",
    "    r_2d = grid[None, :]**2 + grid[:, None]**2\n",
    "    mask = r_2d < radius**2\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def add_noise(img, image_params):\n",
    "\n",
    "    mask = circular_mask(n_pixels=img.shape[0], radius=image_params[\"RADIUS_MASK\"])\n",
    "\n",
    "    signal_std = img[mask].pow(2).mean().sqrt()\n",
    "\n",
    "    if isinstance(image_params[\"SNR\"], float):\n",
    "        snr = image_params[\"SNR\"]\n",
    "\n",
    "    elif isinstance(image_params[\"SNR\"], list) and len(image_params[\"SNR\"]) == 2:\n",
    "        snr = np.random.uniform(low=image_params[\"SNR\"][0], high=image_params[\"SNR\"][1])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"SNR should be a single value or a list of [min_defocus, max_defocus]\")\n",
    "\n",
    "    noise_std = signal_std / np.sqrt(snr)\n",
    "\n",
    "    img_noise = img + torch.distributions.normal.Normal(0, noise_std).sample(img.shape)\n",
    "\n",
    "    return img_noise\n",
    "\n",
    "\n",
    "def add_gradient_noise(img, image_params):\n",
    "\n",
    "    mask = circular_mask(n_pixels=img.shape[0], radius=image_params[\"RADIUS_MASK\"])\n",
    "\n",
    "    signal_std = img[mask].pow(2).mean().sqrt()\n",
    "    noise_std = signal_std / np.sqrt(image_params[\"SNR\"])\n",
    "    \n",
    "    noise = torch.stack(\n",
    "        [\n",
    "            torch.distributions.normal.Normal(0, signal_std / np.sqrt(snr)).sample([img.shape[0],]) \n",
    "            for snr in np.logspace(-1, -2, img.shape[0])\n",
    "        ],\n",
    "        dim=1\n",
    "    )\n",
    "    \n",
    "    img_noise = img + noise\n",
    "\n",
    "    return img_noise\n",
    "\n",
    "\n",
    "def add_colored_noise(img, image_params):\n",
    "    image_L = img.shape[0]\n",
    "\n",
    "    mask = circular_mask(n_pixels=img.shape[0], radius=image_params[\"RADIUS_MASK\"])\n",
    "\n",
    "    signal_std = img[mask].pow(2).mean().sqrt()\n",
    "    noise_std = signal_std / np.sqrt(image_params[\"SNR\"])\n",
    "    \n",
    "    img_noise = torch.distributions.normal.Normal(0, noise_std).sample(img.shape)\n",
    "    fft_noise = torch.fft.fft2(img_noise)\n",
    "\n",
    "    noise_scale = 1.5\n",
    "    along_x, along_y = np.linspace(-1, 1, image_L), np.linspace(-1, 1, image_L)\n",
    "    mesh_x, mesh_y = np.meshgrid(along_x, along_y)\n",
    "    f = torch.zeros((image_L, image_L))\n",
    "\n",
    "    for ix in range(image_L):\n",
    "        for iy in range(image_L):\n",
    "            f[ix, iy] = np.abs(mesh_x[ix, iy])**noise_scale + np.abs(mesh_y[ix, iy])**noise_scale\n",
    "\n",
    "    t = torch.abs(torch.fft.ifft2(fft_noise / f))\n",
    "\n",
    "    noise_scale = 1.0 / (t.max() - t.median())\n",
    "    t = ((t - t.median()) * noise_scale) + 1\n",
    "\n",
    "    img_noise = torch.distributions.normal.Normal(0, noise_std * t).sample()\n",
    "    return img_noise + img\n",
    "\n",
    "\n",
    "def add_shot_noise(image, image_params, noise_scale=1):\n",
    "\n",
    "    norm_img = image - image.min()\n",
    "    shot_noise = torch.poisson(norm_img * noise_scale)\n",
    "    \n",
    "    shot_image = norm_img * noise_scale + shot_noise\n",
    "\n",
    "    return norm_img * noise_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb565281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = add_shot_noise(image_ctf, image_params, noise_scale=1e4)\n",
    "#_ = plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5b9c3-bc7c-414e-b305-0e869c3a99bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = add_noise(image_ctf, image_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25738586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = add_colored_noise(image_ctf, image_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(add_colored_noise(image, image_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da889ed7-58b9-4031-b057-27e29de60500",
   "metadata": {},
   "source": [
    "## Add random shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d4d0f9-12c4-4dc2-b48d-e181b76d5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_shift(padded_image, image_params):\n",
    "\n",
    "    shift_x = int(torch.ceil(image_params[\"N_PIXELS\"] * 0.1 * (2 * torch.rand(1) - 1)))\n",
    "    shift_y = int(torch.ceil(image_params[\"N_PIXELS\"] * 0.1 * (2 * torch.rand(1) - 1)))\n",
    "\n",
    "    pad_width = int(np.ceil(image_params[\"N_PIXELS\"] * 0.1)) + 1\n",
    "\n",
    "    low_ind_x = pad_width - shift_x\n",
    "    high_ind_x = padded_image.shape[0] - pad_width - shift_x\n",
    "\n",
    "    low_ind_y = pad_width - shift_y\n",
    "    high_ind_y = padded_image.shape[0] - pad_width - shift_y\n",
    "\n",
    "    shifted_image = padded_image[low_ind_x:high_ind_x, low_ind_y:high_ind_y]\n",
    "\n",
    "    return shifted_image\n",
    "\n",
    "\n",
    "def apply_no_shift(padded_image, image_params):\n",
    "\n",
    "    pad_width = int(np.ceil(image_params[\"N_PIXELS\"] * 0.1)) + 1\n",
    "\n",
    "    low_ind_x = pad_width\n",
    "    high_ind_x = padded_image.shape[0] - pad_width\n",
    "\n",
    "    low_ind_y = pad_width\n",
    "    high_ind_y = padded_image.shape[0] - pad_width\n",
    "\n",
    "    shifted_image = padded_image[low_ind_x:high_ind_x, low_ind_y:high_ind_y]\n",
    "\n",
    "    return shifted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57391707-34f8-4dfa-a2fd-268121b1f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = apply_random_shift(image, image_params)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae58b27-28f8-4a87-af1a-eda2b7cc776f",
   "metadata": {},
   "source": [
    "## Normalize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c3896-19b3-44be-a2b7-107982e2ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_normalize_image(image):\n",
    "\n",
    "    mean_img = torch.mean(image)\n",
    "    std_img = torch.std(image)\n",
    "\n",
    "    return (image - mean_img) / std_img\n",
    "\n",
    "image = gaussian_normalize_image(image).to(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_pixel = round(image_params[\"N_PIXELS\"] * margin_ratio)\n",
    "x_shift, y_shift = np.random.randint(low=-10, high=10, size=(2,))\n",
    "low_x, high_x = extra_pixel // 2 + x_shift, extra_pixel // 2 + image_params[\"N_PIXELS\"] + x_shift\n",
    "low_y, high_y = extra_pixel // 2 + x_shift, extra_pixel // 2 + image_params[\"N_PIXELS\"] + x_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00194f00-8563-450f-ad18-0221e5872c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(image[low_x: high_x, low_y: high_y], vmax=4, vmin=-4, cmap='binary')\n",
    "plt.imshow(image[low_x: high_x, low_y: high_y], vmax=4, vmin=-4, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryo_sbi.inference.models import build_models\n",
    "import json\n",
    "train_config = json.load(open(\"../experiments/benchmark_hsp90/resnet18_encoder.json\"))\n",
    "estimator = build_models.build_npe_flow_model(train_config)\n",
    "estimator.load_state_dict(torch.load('../experiments/benchmark_hsp90/posterior_hsp90.estimator'))\n",
    "estimator.cuda()\n",
    "estimator.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryo_sbi.utils.estimator_utils import sample_posterior\n",
    "test_image = image[low_x: high_x, low_y: high_y]\n",
    "samples = sample_posterior(estimator, test_image.unsqueeze(0), num_samples=10000, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b1506",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(samples.flatten(), bins=np.arange(0, 20, 0.3), density=True)\n",
    "_ = plt.vlines(10, 0, 0.4, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "from cryo_sbi.wpa_simulator.ctf import calc_ctf, apply_ctf\n",
    "from cryo_sbi.wpa_simulator.image_generation import gen_img, gen_quat\n",
    "from cryo_sbi.wpa_simulator.noise import add_noise\n",
    "from cryo_sbi.wpa_simulator.normalization import gaussian_normalize_image\n",
    "from cryo_sbi.wpa_simulator.padding import pad_image\n",
    "from cryo_sbi.wpa_simulator.shift import apply_no_shift, apply_random_shift\n",
    "from cryo_sbi.wpa_simulator.validate_image_config import check_params\n",
    "\n",
    "\n",
    "class CryoEmSimulator:\n",
    "    def __init__(self, config_fname):\n",
    "        self._load_params(config_fname)\n",
    "        self._load_models()\n",
    "        self.rot_mode = None\n",
    "        self.quaternions = None\n",
    "        self._config_rotations()\n",
    "        self._pad_width = int(np.ceil(self.config[\"N_PIXELS\"] * 0.1)) + 1\n",
    "\n",
    "    def _load_params(self, config_fname):\n",
    "        config = json.load(open(config_fname))\n",
    "        check_params(config)\n",
    "        self.config = config\n",
    "\n",
    "    def _load_models(self):\n",
    "        if \"hsp90\" in self.config[\"MODEL_FILE\"]:\n",
    "            self.models = np.load(self.config[\"MODEL_FILE\"])[:, 0]\n",
    "\n",
    "        elif \"6wxb\" in self.config[\"MODEL_FILE\"]:\n",
    "            self.models = np.load(self.config[\"MODEL_FILE\"])\n",
    "\n",
    "        elif \"square\" in self.config[\"MODEL_FILE\"]:\n",
    "            self.models = np.transpose(\n",
    "                np.load(self.config[\"MODEL_FILE\"]).diagonal(), [2, 0, 1]\n",
    "            )\n",
    "        print(self.config[\"MODEL_FILE\"])\n",
    "\n",
    "    def _config_rotations(self):\n",
    "        if isinstance(self.config[\"ROTATIONS\"], bool):\n",
    "            if self.config[\"ROTATIONS\"]:\n",
    "                self.rot_mode = \"random\"\n",
    "\n",
    "        elif isinstance(self.config[\"ROTATIONS\"], str):\n",
    "            self.rot_mode = \"list\"\n",
    "            self.quaternions = np.loadtxt(self.config[\"ROTATIONS\"], skiprows=1)\n",
    "\n",
    "            assert (\n",
    "                self.quaternions.shape[1] == 4\n",
    "            ), \"Quaternion shape is not 4. Corrupted file?\"\n",
    "\n",
    "    @property\n",
    "    def max_index(self):\n",
    "        return len(self.models) - 1\n",
    "    \n",
    "    def _gen_electron_density(self, index, quaternion):\n",
    "        index = int(torch.round(index))\n",
    "        coord = np.copy(self.models[index])\n",
    "        if quaternion is not None:\n",
    "            rot_mat = Rotation.from_quat(quaternion).as_matrix()\n",
    "            coord = np.matmul(rot_mat, coord)\n",
    "        return coord\n",
    "    \n",
    "\n",
    "    def _add_local_micrograp(self, num_particles):\n",
    "        coords = []\n",
    "        for i in range(num_particles):\n",
    "            quaternion = gen_quat()\n",
    "            index = torch.randint(low=0, high=self.max_index, size=(), dtype=torch.float)\n",
    "            coord = self._gen_electron_density(index, quaternion)\n",
    "            r = np.random.uniform(low=120, high=180)\n",
    "            phi = np.random.uniform(low=0, high=2*np.pi)\n",
    "            coord += np.array([r*np.cos(phi), r*np.sin(phi), 0]).reshape(-1, 1)\n",
    "            coords.append(coord)\n",
    "        return np.concatenate(coords, axis=1)\n",
    "    \n",
    "\n",
    "    def _gen_image_density(self, index, quaternion, num_noise_particles=None):\n",
    "        main_particle = self._gen_electron_density(index, quaternion)\n",
    "        if num_noise_particles is not None:\n",
    "            num_noise_particles = self._add_local_micrograp(num_noise_particles)\n",
    "            return np.concatenate((main_particle, num_noise_particles), axis=1)\n",
    "        else:\n",
    "            return main_particle\n",
    "\n",
    "    def _simulator_with_quat(self, index, quaternion, seed):\n",
    "        coord = self._gen_image_density(index, quaternion, num_noise_particles=30)\n",
    "\n",
    "        image = gen_img(coord, self.config)\n",
    "        image = pad_image(image, self.config)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "\n",
    "        if self.config[\"CTF\"]:\n",
    "            image = apply_ctf(image, calc_ctf(self.config))\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "\n",
    "        if self.config[\"NOISE\"]:\n",
    "            image = add_noise(image, self.config, seed)\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "\n",
    "        if self.config[\"SHIFT\"]:\n",
    "            image = apply_random_shift(image, self.config, seed)\n",
    "        else:\n",
    "            image = apply_no_shift(image, self.config)\n",
    "\n",
    "        image = gaussian_normalize_image(image)\n",
    "\n",
    "        return image.to(dtype=torch.float)\n",
    "\n",
    "\n",
    "    def simulator(self, index, seed=None):\n",
    "        if self.rot_mode == \"random\":\n",
    "            quat = gen_quat()\n",
    "        elif self.rot_mode == \"list\":\n",
    "            quat = self.quaternions[np.random.randint(0, self.quaternions.shape[0])]\n",
    "        else:\n",
    "            quat = None\n",
    "\n",
    "        image = self._simulator_with_quat(index, quat, seed)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca60b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = CryoEmSimulator('../experiments/6wxb/image_params_training.json')\n",
    "sim.config['SNR'] = 0.1\n",
    "#sim.config['NOISE'] = False\n",
    "#sim.config['CTF'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eacff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sim.simulator(torch.tensor(0.0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryo_sbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1391d301e9aa4dc24331c4a52095d8473e5107d84c03241f78234deb9fd2437e"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
