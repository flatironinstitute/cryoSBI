{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d3bbe-f081-467b-9a51-f993cd7dea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "from lampe.data import JointLoader\n",
    "from itertools import islice\n",
    "from tqdm import tqdm\n",
    "from lampe.diagnostics import expected_coverage_mc\n",
    "from lampe.plots import coverage_plot\n",
    "\n",
    "from cryo_sbi.inference.models import build_models\n",
    "from cryo_sbi import CryoEmSimulator\n",
    "from cryo_sbi.inference import priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '23_03_21_final_posterior'      # File name \n",
    "data_dir = \"../experiments/benchmark_hsp90/results/raw_data/\"\n",
    "plot_dir = \"../experiments/benchmark_hsp90/results/plots/\"\n",
    "config_dir = \"../experiments/benchmark_hsp90/\"\n",
    "num_samples_stats = 20000           # Number of simulations for computing posterior stats\n",
    "num_samples_SBC = 10000             # Number of simulations for SBC\n",
    "num_posterior_samples_SBC = 4096    # Number of posterior samples for each SBC simulation\n",
    "num_samples_posterior = 50000       # Number of samples to draw from posterior\n",
    "batch_size_sampling = 100           # Batch size for sampling posterior\n",
    "num_workers = 24                    # Number of CPU cores\n",
    "device = 'cuda'                     # Device for computations\n",
    "save_data = True\n",
    "save_figures = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff02f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_std_mean(image_params, estimator):\n",
    "\n",
    "    cryosbi = CryoEmSimulator(image_params)\n",
    "    indices = priors.get_uniform_prior_1d(cryosbi.max_index).sample((num_samples_stats,))\n",
    "    images = torch.stack([cryosbi.simulator(index) for index in indices], dim=0)\n",
    "\n",
    "    theta_samples = []\n",
    "    with torch.no_grad():\n",
    "        for batched_images in torch.split(images, split_size_or_sections=batch_size_sampling, dim=0):\n",
    "            samples = estimator.sample(\n",
    "                batched_images.cuda(non_blocking=True),\n",
    "                shape=(num_samples_posterior,)\n",
    "            ).cpu()\n",
    "            theta_samples.append(\n",
    "                samples.reshape(-1, batch_size_sampling)\n",
    "            )\n",
    "        samples = torch.cat(theta_samples, dim=1)\n",
    "\n",
    "    mean_distance = (samples.mean(dim=0) - indices.reshape(-1)).numpy()\n",
    "    posterior_quantiles = np.quantile(samples.numpy(), [0.025, 0.975], axis=0)\n",
    "    confidence_widths = (posterior_quantiles[1] - posterior_quantiles[0]).flatten()\n",
    "\n",
    "    return mean_distance, confidence_widths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1226dd-53f1-40db-82a7-657c60a8e104",
   "metadata": {},
   "source": [
    "## Load cryo-em simulator and posterior with correct config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb23c1-3229-48a7-a965-deb74277e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi = CryoEmSimulator(config_dir + \"image_params_training.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ee74f-9a78-4c27-bd7f-14ec441de8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = json.load(open(config_dir + \"resnet18_encoder.json\"))\n",
    "estimator = build_models.build_npe_flow_model(train_config)\n",
    "estimator.load_state_dict(torch.load(config_dir + \"posterior_hsp90.estimator\"))\n",
    "estimator.cuda()\n",
    "estimator.eval();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "488a4635-ea67-4728-b016-a9ecebe23e4a",
   "metadata": {},
   "source": [
    "## Testing posterior on single images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d28d3-0ec6-4928-b825-216f071740d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.tensor(np.arange(0, cryosbi.max_index + 1, 1), dtype=float)\n",
    "images = torch.stack([cryosbi.simulator(index) for index in indices], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f924d-8f2c-4c32-b15d-f23d2b805a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples = []\n",
    "with torch.no_grad():\n",
    "    for batched_images in torch.split(images, split_size_or_sections=batch_size_sampling, dim=0):\n",
    "        samples = estimator.sample(\n",
    "            batched_images.cuda(non_blocking=True),\n",
    "            shape=(num_samples_posterior,)\n",
    "        ).cpu()\n",
    "        theta_samples.append(\n",
    "            samples\n",
    "        )\n",
    "    samples = torch.cat(theta_samples, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3496026",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    torch.save(\n",
    "        {\n",
    "        \"indices\": indices,\n",
    "        \"images\": images,\n",
    "        \"posterior_samples\": samples\n",
    "        },\n",
    "        f'{data_dir}{file_name}_snr01_examples.pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4133ac-b50e-4d37-8b78-2732d6ebeb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(10, 8))\n",
    "for idx, ax in enumerate(axes.reshape(-1)):\n",
    "    ax.imshow(images[idx], vmax=5, vmin=-5)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.text(10, 20, str(int(indices[idx].item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add5831-d35d-4a19-b422-e0c4f03b98ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(10, 8), sharex=True)\n",
    "for idx, ax in enumerate(axes.reshape(1, -1)[0]):\n",
    "    ax.hist(samples[:, idx].numpy(), bins=np.arange(0, 20, 0.5), histtype=\"step\", color=\"blue\", label=\"all\")\n",
    "    ax.set_yticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks(range(0, 20, 4))\n",
    "    ax.axvline(indices[idx], color='red')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7213a4a-3a5d-4e04-9edd-d1906ff02818",
   "metadata": {},
   "source": [
    "## Generate images from prior and evaluate posterior for statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15dc9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_confidence_width = posterior_std_mean(f'{config_dir}image_params_training.json', estimator)\n",
    "torch.save(means_confidence_width,f'{data_dir}{file_name}stats_training.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7d9fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for snr in np.logspace(np.log10(0.5), -2, 5):\n",
    "    for defoc in np.linspace(0.5, 2, 4):\n",
    "        means_confidence_width = posterior_std_mean(f'{config_dir}image_params_snr={round(snr, 2)}_defocus={defoc}.json', estimator)\n",
    "        torch.save(means_confidence_width, f'{data_dir}{file_name}stats_snr={round(snr, 2)}_defocus={defoc}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 201, 20):\n",
    "\n",
    "    file_name = f'posterior_hsp90.estimator_epoch={i}'\n",
    "    if i == 200:\n",
    "        file_name = f'posterior_hsp90.estimator'\n",
    "\n",
    "    train_config = json.load(open(config_dir + \"resnet18_encoder.json\"))\n",
    "    estimator = build_models.build_npe_flow_model(train_config)\n",
    "    estimator.load_state_dict(torch.load(config_dir + file_name))\n",
    "    estimator.cuda()\n",
    "    estimator.eval()\n",
    "\n",
    "    means_confidence_width = posterior_std_mean(f'{config_dir}image_params_snr={0.07}_defocus={1.5}.json', estimator)\n",
    "    torch.save(means_confidence_width, f'{data_dir}{file_name}stats_round={i}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a890dc7a-5881-46fa-9ac2-c5a9379d7834",
   "metadata": {},
   "source": [
    "## Compute posterior calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad78bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi = CryoEmSimulator(f\"{config_dir}image_params_training.json\")\n",
    "for i in range(0, 201, 20):\n",
    "\n",
    "    file_name = f'{config_dir}posterior_hsp90.estimator_epoch={i}'\n",
    "    if i == 200:\n",
    "        file_name = f'{config_dir}posterior_hsp90.estimator'\n",
    "\n",
    "    train_config = json.load(open(config_dir + \"resnet18_encoder.json\"))\n",
    "    estimator = build_models.build_npe_flow_model(train_config)\n",
    "    estimator.load_state_dict(torch.load(config_dir + file_name))\n",
    "    estimator.cuda()\n",
    "    estimator.eval()\n",
    "\n",
    "    loader = JointLoader(\n",
    "        priors.get_uniform_prior_1d(cryosbi.max_index),\n",
    "        cryosbi.simulator,\n",
    "        vectorized=False,\n",
    "        batch_size=1, \n",
    "        num_workers=num_workers,\n",
    "        prefetch_factor=1\n",
    "    )\n",
    "\n",
    "    levels, coverages = expected_coverage_mc(\n",
    "        estimator.flow,\n",
    "        ((estimator.standardize(theta.cuda()), x.cuda()) for theta, x in islice(loader, 20000)),\n",
    "        n = num_posterior_samples_SBC\n",
    "    )\n",
    "\n",
    "    torch.save([levels, coverages], f'{data_dir}{file_name}SBC_round={i}.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5050ccaa-fcff-4e37-8255-ed65a172e6a1",
   "metadata": {},
   "source": [
    "## Generate images from index 10 with known quaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda7e80-e8ed-41ff-beb1-50c66ceca824",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi = CryoEmSimulator(config_dir + \"image_params_snr=0.07_defocus=1.5.json\")\n",
    "quats = torch.from_numpy(np.load('quaternion_list.npy'))\n",
    "indices = 10 * torch.ones(len(quats)).reshape(-1, 1)\n",
    "images = torch.stack([cryosbi._simulator_with_quat(index, quat, seed=None) for index, quat in zip(indices, quats)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ed401-01d7-4bbc-a9bc-c942eea26cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples = []\n",
    "with torch.no_grad():\n",
    "    for batched_images in torch.split(images, split_size_or_sections=batch_size_sampling, dim=0):\n",
    "        samples = estimator.sample(\n",
    "            batched_images.cuda(non_blocking=True),\n",
    "            shape=(num_samples_posterior,)\n",
    "        ).cpu()\n",
    "        theta_samples.append(\n",
    "            samples.reshape(-1, batch_size_sampling)\n",
    "        )\n",
    "samples = torch.cat(theta_samples, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e67dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    torch.save(\n",
    "        {\n",
    "        'indices': indices,\n",
    "        'images': images,\n",
    "        'posterior_samples': samples\n",
    "        },\n",
    "        f\"{data_dir}{file_name}_quats.pt\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryo_sbi",
   "language": "python",
   "name": "cryo_sbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
