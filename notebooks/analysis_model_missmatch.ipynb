{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11d3bbe-f081-467b-9a51-f993cd7dea8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingeldein/anaconda3/envs/cryo_sbi/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "from lampe.data import JointLoader\n",
    "from lampe.diagnostics import expected_coverage_mc\n",
    "from lampe.plots import coverage_plot\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "\n",
    "from cryo_sbi.inference.models import build_models\n",
    "from cryo_sbi import CryoEmSimulator\n",
    "from cryo_sbi.inference import priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1d927f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 128, 128).ndim == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa12d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"23_03_17_missmatch\"  # File name\n",
    "data_dir = \"../experiments/benchmark_hsp90/results/raw_data/\"\n",
    "config_dir = \"../experiments/benchmark_hsp90/\"\n",
    "num_samples_stats = 20000  # Number of simulations for computing posterior stats\n",
    "num_samples_SBC = 10000  # Number of simulations for SBC\n",
    "num_posterior_samples_SBC = 4096  # Number of posterior samples for each SBC simulation\n",
    "num_samples_posterior = 50000  # Number of samples to draw from posterior\n",
    "num_samples_umap = 2000  # Number of simualtions for UMAP analysis\n",
    "batch_size_sampling = 100  # Batch size for sampling posterior\n",
    "batch_size_latent = 1000  # Batch size for calculating latent representation\n",
    "num_workers = 24  # Number of CPU cores\n",
    "device = \"cuda\"  # Device for computations\n",
    "save_data = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f1226dd-53f1-40db-82a7-657c60a8e104",
   "metadata": {},
   "source": [
    "## Load cryo-em simulator and posterior with correct config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb23c1-3229-48a7-a965-deb74277e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi = CryoEmSimulator(config_dir + \"image_params_training.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ee74f-9a78-4c27-bd7f-14ec441de8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = json.load(open(config_dir + \"resnet18_encoder.json\"))\n",
    "estimator = build_models.build_npe_flow_model(train_config)\n",
    "estimator.load_state_dict(torch.load(config_dir + \"posterior_hsp90.estimator\"))\n",
    "estimator.cuda()\n",
    "estimator.eval();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7213a4a-3a5d-4e04-9edd-d1906ff02818",
   "metadata": {},
   "source": [
    "## Compute posterior accuracy and precision for structre missmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c6abe-74fc-4ca6-a29f-36e89e89a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = np.load(\n",
    "    json.load(open(config_dir + \"image_params_training.json\"))[\"MODEL_FILE\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ef49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(5):\n",
    "    cryosbi.models = models[:, row]\n",
    "\n",
    "    indices = priors.get_uniform_prior_1d(cryosbi.max_index).sample(\n",
    "        (num_samples_stats,)\n",
    "    )\n",
    "    images = torch.stack([cryosbi.simulator(index) for index in indices], dim=0)\n",
    "\n",
    "    theta_samples = []\n",
    "    with torch.no_grad():\n",
    "        for batched_images in torch.split(\n",
    "            images, split_size_or_sections=batch_size_sampling, dim=0\n",
    "        ):\n",
    "            samples = estimator.sample(\n",
    "                batched_images.cuda(non_blocking=True), shape=(num_samples_posterior,)\n",
    "            ).cpu()\n",
    "            theta_samples.append(samples.reshape(-1, batch_size_sampling))\n",
    "    samples = torch.cat(theta_samples, dim=1)\n",
    "\n",
    "    mean_distance = (samples.mean(dim=0) - indices.reshape(-1)).numpy()\n",
    "    posterior_quantiles = np.quantile(samples.numpy(), [0.025, 0.975], axis=0)\n",
    "    confidence_widths = posterior_quantiles[1] - posterior_quantiles[0]\n",
    "\n",
    "    if save_data:\n",
    "        np.save(\n",
    "            f\"{data_dir}{file_name}_confidence_widths_r={row}.npy\",\n",
    "            np.array(confidence_widths),\n",
    "        )\n",
    "        np.save(f\"{data_dir}{file_name}_mean_distance_r={row}.npy\", mean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bae07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi.models = models[:, 4]\n",
    "indices = priors.get_unirom_prior_1d(cryosbi.max_index).sample((num_samples_umap,))\n",
    "images_wrong_row = torch.stack([cryosbi.simulator(index) for index in indices], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fdddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples = []\n",
    "with torch.no_grad():\n",
    "    for batched_images in torch.split(\n",
    "        images_wrong_row, split_size_or_sections=batch_size_sampling, dim=0\n",
    "    ):\n",
    "        samples = estimator.sample(\n",
    "            batched_images.cuda(non_blocking=True), shape=(num_samples_posterior,)\n",
    "        ).cpu()\n",
    "        theta_samples.append(samples.reshape(-1, batch_size_sampling))\n",
    "samples = torch.cat(theta_samples, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    torch.save(\n",
    "        {\"indices\": indices, \"images\": images_wrong_row, \"posterior_samples\": samples},\n",
    "        f\"{data_dir}{file_name}_row4.pt\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a890dc7a-5881-46fa-9ac2-c5a9379d7834",
   "metadata": {},
   "source": [
    "## Compute posterior calibration under model missspecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034912d5-3bbf-486d-999a-314a8fc617e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_levels = []\n",
    "all_coverages = []\n",
    "\n",
    "for i in range(5):\n",
    "    cryosbi.models = models[:, i]\n",
    "    loader = JointLoader(\n",
    "        priors.get_unirom_prior_1d(cryosbi.max_index),\n",
    "        cryosbi.simulator,\n",
    "        vectorized=False,\n",
    "        batch_size=1,\n",
    "        num_workers=num_workers,\n",
    "        prefetch_factor=1,\n",
    "    )\n",
    "\n",
    "    estimator.cuda()\n",
    "    estimator.eval()\n",
    "\n",
    "    levels, coverages = expected_coverage_mc(\n",
    "        estimator.flow,\n",
    "        (\n",
    "            (estimator.standardize(theta.cuda()), x.cuda())\n",
    "            for theta, x in islice(loader, num_samples_SBC)\n",
    "        ),\n",
    "        n=num_posterior_samples_SBC,\n",
    "    )\n",
    "\n",
    "    all_levels.append(levels)\n",
    "    all_coverages.append(coverages)\n",
    "\n",
    "all_levels = torch.stack(all_levels, dim=1)\n",
    "all_coverages = torch.stack(all_coverages, dim=1)\n",
    "\n",
    "if save_data:\n",
    "    torch.save([all_levels, all_coverages], f\"{data_dir}{file_name}_sbc_rows\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a92bb1a4",
   "metadata": {},
   "source": [
    "## Compute posterior accuracy and precision for SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07634e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset simulator\n",
    "cryosbi = CryoEmSimulator(config_dir + \"image_params_snr01_128.json\")\n",
    "snrs = np.logspace(-0.5, -1.5, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ef49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for snr in snrs:\n",
    "    cryosbi.config[\"SNR\"] = snr\n",
    "\n",
    "    indices = priors.get_unirom_prior_1d(cryosbi.max_index).sample((num_samples_stats,))\n",
    "    images = torch.stack([cryosbi.simulator(index) for index in indices], dim=0)\n",
    "\n",
    "    theta_samples = []\n",
    "    with torch.no_grad():\n",
    "        for batched_images in torch.split(\n",
    "            images, split_size_or_sections=batch_size_sampling, dim=0\n",
    "        ):\n",
    "            samples = estimator.sample(\n",
    "                batched_images.cuda(non_blocking=True), shape=(num_samples_posterior,)\n",
    "            ).cpu()\n",
    "            theta_samples.append(samples.reshape(-1, batch_size_sampling))\n",
    "    samples = torch.cat(theta_samples, dim=1)\n",
    "\n",
    "    mean_distance = (samples.mean(dim=0) - indices.reshape(-1)).numpy()\n",
    "    posterior_quantiles = np.quantile(samples.numpy(), [0.025, 0.975], axis=0)\n",
    "    confidence_widths = posterior_quantiles[1] - posterior_quantiles[0]\n",
    "\n",
    "    if save_data:\n",
    "        np.save(\n",
    "            f\"{data_dir}{file_name}_confidence_widths_snr={snr}.npy\",\n",
    "            np.array(confidence_widths),\n",
    "        )\n",
    "        np.save(f\"{data_dir}{file_name}_mean_distance_snr={snr}.npy\", mean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi.config[\"SNR\"] = 0.03\n",
    "indices = priors.get_unirom_prior_1d(cryosbi.max_index).sample((num_samples_umap,))\n",
    "images_wrong_snr = torch.stack([cryosbi.simulator(index) for index in indices], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6fb83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples = []\n",
    "with torch.no_grad():\n",
    "    for batched_images in torch.split(\n",
    "        images_wrong_snr, split_size_or_sections=batch_size_sampling, dim=0\n",
    "    ):\n",
    "        samples = estimator.sample(\n",
    "            batched_images.cuda(non_blocking=True), shape=(num_samples_posterior,)\n",
    "        ).cpu()\n",
    "        theta_samples.append(samples.reshape(-1, batch_size_sampling))\n",
    "samples = torch.cat(theta_samples, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f276384",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    torch.save(\n",
    "        {\"indices\": indices, \"images\": images_wrong_row, \"posterior_samples\": samples},\n",
    "        f\"{data_dir}{file_name}_row4.pt\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_levels = []\n",
    "all_coverages = []\n",
    "\n",
    "for snr in snrs:\n",
    "    cryosbi.config[\"SNR\"] = snr\n",
    "    loader = JointLoader(\n",
    "        priors.get_unirom_prior_1d(cryosbi.max_index),\n",
    "        cryosbi.simulator,\n",
    "        vectorized=False,\n",
    "        batch_size=1,\n",
    "        num_workers=24,\n",
    "        prefetch_factor=1,\n",
    "    )\n",
    "\n",
    "    levels, coverages = expected_coverage_mc(\n",
    "        estimator.flow,\n",
    "        (\n",
    "            (estimator.standardize(theta.cuda()), x.cuda())\n",
    "            for theta, x in islice(loader, num_samples_SBC)\n",
    "        ),\n",
    "        n=num_posterior_samples_SBC,\n",
    "    )\n",
    "\n",
    "    all_levels.append(levels)\n",
    "    all_coverages.append(coverages)\n",
    "\n",
    "all_levels = torch.stack(all_levels, dim=1)\n",
    "all_coverages = torch.stack(all_coverages, dim=1)\n",
    "\n",
    "if save_data:\n",
    "    torch.save([all_levels, all_coverages], f\"{data_dir}{file_name}_sbc_snr\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40f9ccfc",
   "metadata": {},
   "source": [
    "## Model missspecification non-Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e28800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulator_colored_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi_colored_noise = simulator_colored_noise.CryoEmSimulatorColoredNoise(\n",
    "    config_dir + \"image_params_snr01_128.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = priors.get_unirom_prior_1d(cryosbi_colored_noise.max_index).sample(\n",
    "    (num_samples_stats,)\n",
    ")\n",
    "images = torch.stack(\n",
    "    [cryosbi_colored_noise.simulator(index) for index in indices], dim=0\n",
    ")\n",
    "\n",
    "theta_samples = []\n",
    "with torch.no_grad():\n",
    "    for batched_images in torch.split(\n",
    "        images, split_size_or_sections=batch_size_sampling, dim=0\n",
    "    ):\n",
    "        samples = estimator.sample(\n",
    "            batched_images.cuda(non_blocking=True), shape=(num_samples_posterior,)\n",
    "        ).cpu()\n",
    "        theta_samples.append(samples.reshape(-1, batch_size_sampling))\n",
    "samples = torch.cat(theta_samples, dim=1)\n",
    "\n",
    "mean_distance = (samples.mean(dim=0) - indices.reshape(-1)).numpy()\n",
    "posterior_quantiles = np.quantile(samples.numpy(), [0.025, 0.975], axis=0)\n",
    "confidence_widths = posterior_quantiles[1] - posterior_quantiles[0]\n",
    "\n",
    "if save_data:\n",
    "    np.save(\n",
    "        f\"{data_dir}{file_name}_confidence_widths_gradient_snr.npy\",\n",
    "        np.array(confidence_widths),\n",
    "    )\n",
    "    np.save(f\"{data_dir}{file_name}_mean_distance_gradient_snr.npy\", mean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = JointLoader(\n",
    "    priors.get_unirom_prior_1d(cryosbi_colored_noise.max_index),\n",
    "    cryosbi_colored_noise.simulator,\n",
    "    vectorized=False,\n",
    "    batch_size=1,\n",
    "    num_workers=num_workers,\n",
    "    prefetch_factor=1,\n",
    ")\n",
    "\n",
    "levels, coverages = expected_coverage_mc(\n",
    "    estimator.flow,\n",
    "    (\n",
    "        (estimator.standardize(theta.cuda()), x.cuda())\n",
    "        for theta, x in islice(loader, num_samples_SBC)\n",
    "    ),\n",
    "    n=num_posterior_samples_SBC,\n",
    ")\n",
    "\n",
    "if save_data:\n",
    "    torch.save([levels, coverages], f\"{data_dir}{file_name}_sbc_gradient_snr.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f047548d",
   "metadata": {},
   "source": [
    "## Model missspecification: No particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9023bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_no_particle = torch.randn((num_samples_umap, 1, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed220107",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images_no_particle[0].reshape(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples = []\n",
    "with torch.no_grad():\n",
    "    for batched_images in torch.split(\n",
    "        images_no_particle, split_size_or_sections=batch_size_sampling, dim=0\n",
    "    ):\n",
    "        samples = estimator.sample(\n",
    "            batched_images.cuda(non_blocking=True), shape=(num_samples_posterior,)\n",
    "        ).cpu()\n",
    "        theta_samples.append(samples.reshape(-1, batch_size_sampling))\n",
    "samples = torch.cat(theta_samples, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[1].hist(\n",
    "    samples[:, :10].numpy(),\n",
    "    bins=np.arange(0, 10, 0.1),\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    linewidth=2,\n",
    ")\n",
    "axes[1].set_xlabel(\"Index\")\n",
    "axes[0].imshow(images_no_particle[0].reshape(128, 128))\n",
    "plt.savefig(f\"Posterior_no_particles_{file_name}.pdf\", dpi=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f64f856",
   "metadata": {},
   "source": [
    "## Model missspecification: Wrong particles (One arm of Hsp90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi = CryoEmSimulator(data_dir + \"image_params_snr01_128.json\")\n",
    "cryosbi.models = models[:, 0, :, :603]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daba4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cryosbi.simulator(torch.tensor([10.0]))\n",
    "samples = estimator.sample(test_image.cuda(), shape=(100000,)).cpu()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(test_image.reshape(128, 128))\n",
    "_ = axes[1].hist(\n",
    "    samples.flatten().numpy(),\n",
    "    bins=np.arange(0, 20, 0.1),\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    linewidth=2,\n",
    ")\n",
    "fig.savefig(\"Example_wrong_particle.pdf\", dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b0c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = priors.get_unirom_prior_1d(cryosbi.get_max_index()).sample(\n",
    "    (num_samples_umap,)\n",
    ")\n",
    "images_wrong_particle = torch.stack(\n",
    "    [cryosbi.simulator(index) for index in indices], dim=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cd2cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples = []\n",
    "with torch.no_grad():\n",
    "    for batched_images in torch.split(\n",
    "        images_wrong_particle, split_size_or_sections=batch_size_sampling, dim=0\n",
    "    ):\n",
    "        samples = estimator.sample(\n",
    "            batched_images.cuda(non_blocking=True), shape=(num_samples_posterior,)\n",
    "        ).cpu()\n",
    "        theta_samples.append(samples.reshape(-1, batch_size_sampling))\n",
    "samples = torch.cat(theta_samples, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd836ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(\n",
    "    samples[:, :20].numpy(),\n",
    "    bins=np.arange(0, 20, 0.1),\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    label=name,\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.xlabel(\"Index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7551b40f-6d36-435d-adfb-5a047d9c1d02",
   "metadata": {},
   "source": [
    "## Detecting model missspecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2aaccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_mstar = [\n",
    "    images_no_particle,\n",
    "    images_wrong_particle,\n",
    "    images_wrong_row,\n",
    "    images_wrong_snr,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_repr_mstar = []\n",
    "with torch.no_grad():\n",
    "    for images in images_mstar:\n",
    "        latent_space_samples = []\n",
    "        for batched_images in torch.split(\n",
    "            images, split_size_or_sections=batch_size_latent, dim=0\n",
    "        ):\n",
    "            samples = estimator.embedding(batched_images.cuda(non_blocking=True)).cpu()\n",
    "            latent_space_samples.append(samples.reshape(batch_size_latent, -1))\n",
    "        latent_repr_mstar.append(torch.cat(latent_space_samples, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77897236",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi = CryoEmSimulator(data_dir + \"image_params_snr01_128.json\")\n",
    "indices = priors.get_unirom_prior_1d(cryosbi.get_max_index()).sample(\n",
    "    (num_samples_umap,)\n",
    ")\n",
    "images = torch.stack([cryosbi.simulator(index) for index in indices], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c042fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_samples = []\n",
    "batch_size = 1000\n",
    "with torch.no_grad():\n",
    "    for batched_images in torch.split(\n",
    "        images, split_size_or_sections=batch_size_latent, dim=0\n",
    "    ):\n",
    "        samples = estimator.embedding(batched_images.cuda(non_blocking=True)).cpu()\n",
    "        latent_space_samples.append(samples.reshape(batch_size_latent, -1))\n",
    "latent_repr_m = torch.cat(latent_space_samples, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples = []\n",
    "with torch.no_grad():\n",
    "    for batched_images in torch.split(\n",
    "        images, split_size_or_sections=batch_size_sampling, dim=0\n",
    "    ):\n",
    "        samples = estimator.sample(\n",
    "            batched_images.cuda(non_blocking=True), shape=(num_samples_posterior,)\n",
    "        ).cpu()\n",
    "        theta_samples.append(samples.reshape(-1, batch_size_sampling))\n",
    "samples = torch.cat(theta_samples, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_quantiles = np.quantile(samples.numpy(), [0.025, 0.975], axis=0)\n",
    "confidence_widths = posterior_quantiles[1] - posterior_quantiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe57459",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_latent_samples = torch.cat((latent_repr_m, *latent_repr_mstar))\n",
    "\n",
    "labels = torch.cat(\n",
    "    (\n",
    "        torch.zeros(10000),\n",
    "        1 * torch.ones(10000),\n",
    "        2 * torch.ones(10000),\n",
    "        3 * torch.ones(10000),\n",
    "        4 * torch.ones(10000),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91600e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "reducer = umap.UMAP(metric=\"euclidean\", n_components=2, n_neighbors=50)\n",
    "embedding = reducer.fit_transform(cat_latent_samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7aab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\n",
    "    \"Ground truth\",\n",
    "    \"No particle\",\n",
    "    \"Wrong particle\",\n",
    "    \"Wrong row (4)\",\n",
    "    \"Wrong SNR (0.03)\",\n",
    "]\n",
    "colors = [\"red\", \"blue\", \"green\", \"yellow\", \"black\"]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "for idx, i in enumerate(\n",
    "    range(0, (len(images_mstar) + 1) * num_samples_umap, num_samples_umap)\n",
    "):\n",
    "    axes[0].scatter(\n",
    "        embedding[i : i + num_samples_umap, 0],\n",
    "        embedding[i : i + num_samples_umap, 1],\n",
    "        label=name[idx],\n",
    "        c=colors[idx],\n",
    "        s=0.1,\n",
    "    )\n",
    "axes[0].legend(fontsize=10, markerscale=10)\n",
    "axes[0].set_ylabel(\"UMAP dimsenion 1\")\n",
    "\n",
    "im1 = axes[1].scatter(\n",
    "    embedding[0:num_samples_umap, 0],\n",
    "    embedding[0:num_samples_umap, 1],\n",
    "    c=indices.numpy(),\n",
    "    s=0.5,\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "fig.colorbar(im1, ax=axes[1], label=\"Index\")\n",
    "axes[1].set_xlabel(\"UMAP dimsenion 2\")\n",
    "\n",
    "im2 = axes[2].scatter(\n",
    "    embedding[0:num_samples_umap, 0],\n",
    "    embedding[0:num_samples_umap, 1],\n",
    "    c=confidence_widths,\n",
    "    s=0.5,\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "fig.colorbar(im2, ax=axes[2], label=\"Width of 95% confidence intervall\")\n",
    "plt.savefig(f\"UMAP_analysis_{file_name}.png\", dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ce3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_posterior(estimator, images, num_samples, batch_size=100, device=\"cpu\"):\n",
    "    theta_samples = []\n",
    "\n",
    "    if images.shape[0] > batch_size:\n",
    "        images = torch.split(images, split_size_or_sections=batch_size, dim=0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image_batch in images:\n",
    "            samples = estimator.sample(\n",
    "                image_batch.to(device, non_blocking=True), shape=(num_samples,)\n",
    "            ).cpu()\n",
    "            theta_samples.append(samples.reshape(-1, batch_size))\n",
    "\n",
    "    return torch.cat(theta_samples, dim=1)\n",
    "\n",
    "\n",
    "def compute_latent_repr(estimator, images, batch_size=1000, device=\"cpu\"):\n",
    "    latent_space_samples = []\n",
    "\n",
    "    if images.shape[0] > batch_size:\n",
    "        images = torch.split(images, split_size_or_sections=batch_size, dim=0)\n",
    "    else:\n",
    "        batch_size = 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image_batch in images:\n",
    "            samples = estimator.embedding(\n",
    "                image_batch.to(device, non_blocking=True)\n",
    "            ).cpu()\n",
    "            latent_space_samples.append(samples.reshape(batch_size, -1))\n",
    "\n",
    "    return torch.cat(latent_space_samples, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3f52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryo_sbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1391d301e9aa4dc24331c4a52095d8473e5107d84c03241f78234deb9fd2437e"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
