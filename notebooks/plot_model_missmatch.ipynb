{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d3bbe-f081-467b-9a51-f993cd7dea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "from lampe.data import JointLoader\n",
    "from lampe.diagnostics import expected_coverage_mc\n",
    "from lampe.plots import coverage_plot\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "\n",
    "from cryo_sbi.inference.models import build_models\n",
    "from cryo_sbi import CryoEmSimulator\n",
    "from cryo_sbi.inference import priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '23_03_17_missmatch'\n",
    "data_dir = \"../experiments/benchmark_hsp90/results/raw_data/\"\n",
    "fig_dir = \"../experiments/benchmark_hsp90/results/plots/\"\n",
    "config_dir = \"../experiments/benchmark_hsp90/\"                   \n",
    "device = 'cuda'                  \n",
    "save_figures = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "labels = [f'Row = {row}' for row in range(5)]\n",
    "file_names_means = [f'{data_dir}{file_name}_mean_distance_r={row}.npy' for row in range(5)]\n",
    "file_names_confidence = [f'{data_dir}{file_name}_confidence_widths_r={row}.npy' for row in range(5)]\n",
    "\n",
    "\n",
    "for file, name in zip(file_names_means, labels):\n",
    "    mean_distances = np.load(file)\n",
    "    axes[0].hist(mean_distances, bins=np.arange(-10, 10, 0.5), histtype='step', density=True, label=name, linewidth=2)\n",
    "axes[0].set_xlabel(r'Posterior mean - ture index', fontsize=13)\n",
    "axes[0].set_yticklabels([])\n",
    "\n",
    "\n",
    "for file, name in zip(file_names_confidence, labels):\n",
    "    confidence_widths = np.load(file)\n",
    "    axes[1].hist(confidence_widths, bins=np.arange(0, 20, 0.5), histtype='step', density=True, label=name, linewidth=2)\n",
    "axes[1].set_xlabel(r'Width of 3$\\sigma$-confidence-intervall', fontsize=13)\n",
    "axes[1].set_yticklabels([])\n",
    "axes[1].legend(fontsize=13)\n",
    "\n",
    "\n",
    "levels, coverages = torch.load(\"../experiments/benchmark_hsp90/results/raw_data/sbc_rows.pt\")\n",
    "axes[2].plot(levels, coverages)\n",
    "axes[2].plot([0, 1], [0, 1], linestyle=\"--\", linewidth=2, color=\"black\")\n",
    "axes[2].set_xlabel('Credible level', fontsize=13)\n",
    "axes[2].set_ylabel('Expected coverage', fontsize=13)\n",
    "\n",
    "if save_figures:\n",
    "    plt.savefig(f'{fig_dir}{file_name}_missspecified_model.pdf', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "snrs = np.logspace(-0.5, -1.5, 9)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "labels = [f'$\\Delta$SNR = {snr-0.1:.3f}' for snr in snrs]\n",
    "file_names_means = [f'{data_dir}{file_name}_mean_distance_snr={snr}.npy' for snr in snrs]\n",
    "file_names_confidence = [f'{data_dir}{file_name}_confidence_widths_snr={snr}.npy' for snr in snrs]\n",
    "\n",
    "\n",
    "for file, name in zip(file_names_means, labels):\n",
    "    mean_distances = np.load(file)\n",
    "    axes[0].hist(mean_distances, bins=np.arange(-15, 20, 0.3), histtype='step', density=True, label=name, linewidth=2)\n",
    "axes[0].set_xlabel(r'Posterior mean - ture index')\n",
    "\n",
    "\n",
    "for file, name in zip(file_names_confidence, labels):\n",
    "    confidence_widths = np.load(file)\n",
    "    axes[1].hist(confidence_widths, bins=np.arange(0, 15, 0.3), histtype='step', density=True, label=name, linewidth=2)\n",
    "axes[1].set_xlabel(r'with of $95\\%-$confidence intervall')\n",
    "axes[1].legend()\n",
    "\n",
    "\n",
    "levels, coverages = torch.load(f'{data_dir}{file_name}_sbc_snr')\n",
    "axes[2].plot(levels, coverages)\n",
    "axes[2].plot([0, 1], [0, 1], linestyle=\"--\", linewidth=2, color=\"black\")\n",
    "axes[2].set_xlabel('Credible level', fontsize=13)\n",
    "axes[2].set_ylabel('Expected coverage', fontsize=13)\n",
    "\n",
    "\n",
    "if save_figures:\n",
    "    plt.savefig(f'{fig_dir}{file_name}_missspecified_snr.pdf', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b1584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4da439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f42b7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a41581d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7403204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74848731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70453d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa12d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'snr01_wideres50_128'    # File name \n",
    "data_dir = \"/\"\n",
    "config_dir = \"../experiments/benchmark_hsp90/\"\n",
    "num_samples_stats = 20000           # Number of simulations for computing posterior stats\n",
    "num_samples_SBC = 10000             # Number of simulations for SBC\n",
    "num_posterior_samples_SBC = 4096    # Number of posterior samples for each SBC simulation\n",
    "num_samples_posterior = 50000       # Number of samples to draw from posterior\n",
    "num_samples_umap = 10000            # Number of simualtions for UMAP analysis\n",
    "batch_size_sampling = 100           # Batch size for sampling posterior\n",
    "batch_size_latent = 1000            # Batch size for calculating latent representation\n",
    "num_workers = 24                    # Number of CPU cores\n",
    "device = 'cuda'                     # Device for computations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1226dd-53f1-40db-82a7-657c60a8e104",
   "metadata": {},
   "source": [
    "## Load cryo-em simulator and posterior with correct config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb23c1-3229-48a7-a965-deb74277e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi = CryoEmSimulator(config_dir + \"image_params_snr01_128.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ee74f-9a78-4c27-bd7f-14ec441de8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = json.load(open(config_dir + \"resnet18_encoder.json\"))\n",
    "estimator = build_models.build_npe_flow_model(train_config)\n",
    "estimator.load_state_dict(torch.load(config_dir + \"resnet18_encoder_snr01.estimator\"))\n",
    "estimator.cuda()\n",
    "estimator.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c6abe-74fc-4ca6-a29f-36e89e89a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = np.load(json.load(open(config_dir + \"image_params_snr01_128.json\"))[\"MODEL_FILE\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7213a4a-3a5d-4e04-9edd-d1906ff02818",
   "metadata": {},
   "source": [
    "## Compute posterior accuracy and precision for structre missmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ef49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(5):\n",
    "    cryosbi.models = models[:, row]\n",
    "\n",
    "    indices = priors.get_unirom_prior_1d(cryosbi.get_max_index()).sample((num_samples_stats,))\n",
    "    images = torch.stack([cryosbi.simulator(index) for index in indices], dim=0)\n",
    "\n",
    "    theta_samples = []\n",
    "    with torch.no_grad():\n",
    "        for batched_images in torch.split(images, split_size_or_sections=batch_size_sampling, dim=0):\n",
    "            samples = estimator.sample(\n",
    "                batched_images.cuda(non_blocking=True),\n",
    "                shape=(num_samples_posterior,)\n",
    "            ).cpu()\n",
    "            theta_samples.append(samples.reshape(-1, batch_size_sampling))\n",
    "    samples = torch.cat(theta_samples, dim=1)\n",
    "\n",
    "    mean_distance = (samples.mean(dim=0) - indices.reshape(-1)).numpy()\n",
    "    posterior_quantiles = np.quantile(samples.numpy(), [0.025, 0.975], axis=0)\n",
    "    confidence_widths = posterior_quantiles[1] - posterior_quantiles[0]\n",
    "\n",
    "    np.save(f'confidence_widths_r={row}_{file_name}.npy', np.array(confidence_widths))\n",
    "    np.save(f'mean_distance_r={row}_{file_name}.npy', mean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b017df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "labels = [f'Row = {row}' for row in range(5)]\n",
    "file_names_means = [f'mean_distance_r={row}_{file_name}.npy' for row in range(5)]\n",
    "file_names_confidence = [f'confidence_widths_r={row}_{file_name}.npy' for row in range(5)]\n",
    "\n",
    "\n",
    "for file, name in zip(file_names_means, labels):\n",
    "    mean_distances = np.load(file)\n",
    "    axes[0].hist(mean_distances, bins=np.arange(-10, 10, 0.5), histtype='step', density=True, label=name, linewidth=2)\n",
    "axes[0].set_xlabel(r'Posterior mean - ture index', fontsize=13)\n",
    "axes[0].legend()\n",
    "\n",
    "\n",
    "for file, name in zip(file_names_confidence, labels):\n",
    "    confidence_widths = np.load(file)\n",
    "    axes[1].hist(confidence_widths, bins=np.arange(0, 15, 0.5), histtype='step', density=True, label=name, linewidth=2)\n",
    "axes[1].set_xlabel(r'Width of 3$\\sigma$-confidence-intervall', fontsize=13)\n",
    "axes[1].legend()\n",
    "\n",
    "\n",
    "plt.savefig(f'missspecified_model_{file_name}.pdf', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bae07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi.models = models[:, 4]\n",
    "indices = priors.get_unirom_prior_1d(cryosbi.get_max_index()).sample((20000,))\n",
    "images_wrong_row = torch.stack([cryosbi.simulator(index) for index in indices], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531cabd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample_posterior(estimator, images_wrong_row, num_samples=50000, batch_size=100, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_quantiles = np.quantile(samples.numpy(), [0.005, 0.995], axis=0)\n",
    "confidence_widths = posterior_quantiles[1] - posterior_quantiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599942cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "off_index = []\n",
    "for idx, index in enumerate(indices):\n",
    "    lower, upper = posterior_quantiles[:, idx] \n",
    "    if index < lower or index > upper:\n",
    "        off_index.append(idx)\n",
    "print(len(off_index)/len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10771db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "for idx, ax in enumerate(axes.reshape(-1)):\n",
    "    ax.hist(samples[:, idx].cpu().flatten().numpy(), bins=np.arange(0, 20, 0.2),histtype='step', density=True, linewidth=1.5)\n",
    "    ax.axvline(indices.reshape(-1)[idx].item(), color='red')\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = estimator.sample(images_wrong_row[:100].cuda(), shape=(50000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 6, figsize=(9, 3))\n",
    "for idx, ax in enumerate(axes[1]):\n",
    "    ax.hist(samples[:, idx+40].cpu().flatten().numpy(), bins=np.arange(0, 20, 0.2),histtype='step', density=True, label=name, linewidth=1.5)\n",
    "    ax.set_yticks([])\n",
    "    ax.axvline(indices.reshape(-1)[idx].item(), color='red')\n",
    "\n",
    "for idx, ax in enumerate(axes[0]):\n",
    "    ax.imshow(images_wrong_row[idx].reshape(128, 128))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "fig.savefig(f'example_missspecified_model_{file_name}.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a890dc7a-5881-46fa-9ac2-c5a9379d7834",
   "metadata": {},
   "source": [
    "## Compute posterior calibration under model missspecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034912d5-3bbf-486d-999a-314a8fc617e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_levels = []\n",
    "all_coverages = []\n",
    "\n",
    "for i in range(5):\n",
    "    cryosbi.models = models[:, i]\n",
    "    loader = JointLoader(\n",
    "        priors.get_unirom_prior_1d(cryosbi.max_index),\n",
    "        cryosbi.simulator,\n",
    "        vectorized=False,\n",
    "        batch_size=1, \n",
    "        num_workers=num_workers,\n",
    "        prefetch_factor=1\n",
    "    )\n",
    "    \n",
    "    estimator.cuda()\n",
    "    estimator.eval()\n",
    "    \n",
    "    levels, coverages = expected_coverage_mc(\n",
    "        estimator.flow,\n",
    "        ((estimator.standardize(theta.cuda()), x.cuda()) for theta, x in islice(loader, num_samples_SBC)),\n",
    "        n = num_posterior_samples_SBC\n",
    "    )\n",
    "    \n",
    "    all_levels.append(levels)\n",
    "    all_coverages.append(coverages)\n",
    "    \n",
    "all_levels = torch.stack(all_levels, dim=1)\n",
    "all_coverages = torch.stack(all_coverages, dim=1)\n",
    "\n",
    "torch.save([all_levels, all_coverages], '../experiments/benchmark_hsp90/results/raw_data/sbc_rows.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1f385a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aab193",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "labels = [f'Row = {row}' for row in range(5)]\n",
    "file_names_means = [f'mean_distance_r={row}_{file_name}.npy' for row in range(5)]\n",
    "file_names_confidence = [f'confidence_widths_r={row}_{file_name}.npy' for row in range(5)]\n",
    "\n",
    "\n",
    "for file, name in zip(file_names_means, labels):\n",
    "    mean_distances = np.load(file)\n",
    "    axes[0].hist(mean_distances, bins=np.arange(-10, 10, 0.5), histtype='step', density=True, label=name, linewidth=2)\n",
    "axes[0].set_xlabel(r'Posterior mean - ture index', fontsize=13)\n",
    "axes[0].set_yticklabels([])\n",
    "axes[0].legend()\n",
    "\n",
    "\n",
    "for file, name in zip(file_names_confidence, labels):\n",
    "    confidence_widths = np.load(file)\n",
    "    axes[1].hist(confidence_widths, bins=np.arange(0, 15, 0.5), histtype='step', density=True, label=name, linewidth=2)\n",
    "axes[1].set_xlabel(r'Width of 3$\\sigma$-confidence-intervall', fontsize=13)\n",
    "axes[1].set_yticklabels([])\n",
    "\n",
    "levels, coverages = torch.load(\"../experiments/benchmark_hsp90/results/raw_data/sbc_rows.pt\")\n",
    "axes[2].plot(levels, coverages)\n",
    "axes[2].plot([0, 1], [0, 1], linestyle=\"--\", linewidth=2, color=\"black\")\n",
    "axes[2].set_xlabel('Credible level', fontsize=13)\n",
    "axes[2].set_ylabel('Expected coverage', fontsize=13)\n",
    "\n",
    "\n",
    "#plt.savefig(f'missspecified_model_{file_name}.pdf', dpi=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a92bb1a4",
   "metadata": {},
   "source": [
    "## Compute posterior accuracy and precision for SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07634e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset simulator\n",
    "cryosbi = CryoEmSimulator(data_dir + \"image_params_snr01_128.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ef49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "snrs = np.logspace(-0.5, -1.5, 9)\n",
    "for snr in snrs:\n",
    "    cryosbi.config['SNR'] = snr\n",
    "\n",
    "    indices = priors.get_unirom_prior_1d(cryosbi.get_max_index()).sample((num_samples_stats,))\n",
    "    images = torch.stack([cryosbi.simulator(index) for index in indices], dim=0)\n",
    "\n",
    "    theta_samples = []\n",
    "    with torch.no_grad():\n",
    "        for batched_images in torch.split(images, split_size_or_sections=batch_size_sampling, dim=0):\n",
    "            samples = estimator.sample(\n",
    "                batched_images.cuda(non_blocking=True), \n",
    "                shape=(num_samples_posterior,)\n",
    "            ).cpu()\n",
    "            theta_samples.append(samples.reshape(-1, batch_size_sampling))\n",
    "    samples = torch.cat(theta_samples, dim=1)\n",
    "\n",
    "    mean_distance = (samples.mean(dim=0) - indices.reshape(-1)).numpy()\n",
    "    posterior_quantiles = np.quantile(samples.numpy(), [0.025, 0.975], axis=0)\n",
    "    confidence_widths = posterior_quantiles[1] - posterior_quantiles[0]\n",
    "\n",
    "    np.save(f'confidence_widths_snr={snr}_{file_name}.npy', np.array(confidence_widths))\n",
    "    np.save(f'mean_distance_snr={snr}_{file_name}.npy', mean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028a86f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "snrs = np.logspace(-0.5, -1.5, 9)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "labels = [f'SNR = {snr-0.1:.3f}' for snr in snrs]\n",
    "file_names_means = [f'mean_distance_snr={snr}_{file_name}.npy' for snr in snrs]\n",
    "file_names_confidence = [f'confidence_widths_snr={snr}_{file_name}.npy' for snr in snrs]\n",
    "\n",
    "\n",
    "for file, name in zip(file_names_means, labels):\n",
    "    mean_distances = np.load(file)\n",
    "    axes[0].hist(mean_distances, bins=np.arange(-15, 20, 0.3), histtype='step', density=True, label=name, linewidth=2)\n",
    "axes[0].set_xlabel(r'Posterior mean - ture index')\n",
    "\n",
    "\n",
    "for file, name in zip(file_names_confidence, labels):\n",
    "    confidence_widths = np.load(file)\n",
    "    axes[1].hist(confidence_widths, bins=np.arange(0, 15, 0.3), histtype='step', density=True, label=name, linewidth=2)\n",
    "axes[1].set_xlabel(r'with of $95\\%-$confidence intervall')\n",
    "axes[1].legend()\n",
    "\n",
    "\n",
    "plt.savefig(f'missspecified_snr_{file_name}.pdf', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi.config['SNR'] = 0.03\n",
    "indices = priors.get_unirom_prior_1d(cryosbi.get_max_index()).sample((num_samples_umap,))\n",
    "images_wrong_snr = torch.stack([cryosbi.simulator(index) for index in indices], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f276384",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = estimator.sample(images_wrong_snr[:100].cuda(), shape=(50000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28743e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 6, figsize=(9, 3))\n",
    "for idx, ax in enumerate(axes[1]):\n",
    "    ax.hist(samples[:, idx+40].cpu().flatten().numpy(), bins=np.arange(0, 20, 0.2),histtype='step', density=True, label=name, linewidth=1.5)\n",
    "    ax.set_yticks([])\n",
    "    ax.axvline(indices.reshape(-1)[idx].item(), color='red')\n",
    "\n",
    "for idx, ax in enumerate(axes[0]):\n",
    "    ax.imshow(images_wrong_snr[idx].reshape(128, 128))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "fig.savefig(f'example_missspecified_snr_{file_name}.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b007c59",
   "metadata": {},
   "source": [
    "## Noise model missspecification misspecified SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_samples = 10000\n",
    "all_levels = []\n",
    "all_coverage = []\n",
    "\n",
    "for snr in snrs:\n",
    "    cryosbi.config['SNR'] = snr\n",
    "    loader = JointLoader(\n",
    "        priors.get_unirom_prior_1d(cryosbi.get_max_index()),\n",
    "        cryosbi.simulator,\n",
    "        vectorized=True,\n",
    "        batch_size=1,\n",
    "        num_workers=24,\n",
    "        prefetch_factor=1\n",
    "    )\n",
    "\n",
    "    levels, coverages = expected_coverage_mc(\n",
    "        estimator.flow,\n",
    "        ((estimator.standardize(theta.cuda()), x.cuda()) for theta, x in islice(loader, num_samples_SBC)),\n",
    "        n = num_posterior_samples_SBC\n",
    "    )\n",
    "    \n",
    "    all_levels.append(levels)\n",
    "    all_coverage.append(coverages)\n",
    "    \n",
    "all_levels = torch.stack(all_levels, dim=1)\n",
    "all_coverage = torch.stack(all_coverage, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0618a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = coverage_plot(\n",
    "    all_levels, all_coverage,\n",
    "    legend=list(map(lambda x: f'SNR = {x:.3f}', np.logspace(-0.5, -1.5, 9))),\n",
    "    figsize=(4.5, 4.5)\n",
    "    )\n",
    "fig.savefig(f'SBC_missspecifed_snr_{file_name}.pdf', dpi=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40f9ccfc",
   "metadata": {},
   "source": [
    "## Model missspecification non-Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e28800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulator_colored_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi_colored_noise = simulator_colored_noise.CryoEmSimulatorColoredNoise(data_dir + \"image_params_snr01_128.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = JointLoader(\n",
    "    priors.get_unirom_prior_1d(cryosbi.get_max_index()),\n",
    "    cryosbi_colored_noise.simulator,\n",
    "    vectorized=True,\n",
    "    batch_size=1,\n",
    "    num_workers=num_workers,\n",
    "    prefetch_factor=1\n",
    ")\n",
    "\n",
    "levels, coverages = expected_coverage_mc(\n",
    "    estimator.flow,\n",
    "    ((estimator.standardize(theta.cuda()), x.cuda()) for theta, x in islice(loader, num_samples_SBC)),\n",
    "    n = num_posterior_samples_SBC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = coverage_plot(levels, coverages)\n",
    "fig.savefig(f'SBC_non_gaussian_snr_{file_name}.pdf', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad0f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cryosbi_colored_noise.simulator(torch.tensor([10.]))\n",
    "samples = estimator.sample(test_image.cuda(), shape=(100000,)).cpu()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[1].hist(samples.flatten().numpy(), bins=np.arange(0, 20, 0.2), histtype='step', linewidth=2, density=True)\n",
    "axes[1].set_xlabel('Index')\n",
    "axes[1].axvline(10, 0, 1, color='red')\n",
    "axes[0].imshow(test_image.reshape(128, 128))\n",
    "plt.savefig('Example_non_gaussian_noise.pdf', dpi=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f047548d",
   "metadata": {},
   "source": [
    "## Model missspecification: No particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9023bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_no_particle = torch.randn((num_samples_umap, 1, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed220107",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images_no_particle[0].reshape(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples = []\n",
    "with torch.no_grad():\n",
    "    for batched_images in torch.split(images_no_particle, split_size_or_sections=batch_size_sampling, dim=0):\n",
    "        samples = estimator.sample(\n",
    "            batched_images.cuda(non_blocking=True),\n",
    "            shape=(num_samples_posterior,)\n",
    "        ).cpu()\n",
    "        theta_samples.append(samples.reshape(-1, batch_size_sampling))\n",
    "samples = torch.cat(theta_samples, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[1].hist(samples[:, :10].numpy(), bins=np.arange(0, 10, 0.1), histtype='step', density=True, linewidth=2)\n",
    "axes[1].set_xlabel('Index')\n",
    "axes[0].imshow(images_no_particle[0].reshape(128, 128))\n",
    "plt.savefig(f'Posterior_no_particles_{file_name}.pdf', dpi=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f64f856",
   "metadata": {},
   "source": [
    "## Model missspecification: Wrong particles (One arm of Hsp90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi = CryoEmSimulator(data_dir + \"image_params_snr01_128.json\")\n",
    "cryosbi.models = models[:, 0, :, :603]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daba4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cryosbi.simulator(torch.tensor([10.]))\n",
    "samples = estimator.sample(test_image.cuda(), shape=(100000,)).cpu()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(test_image.reshape(128, 128))\n",
    "_ = axes[1].hist(samples.flatten().numpy(), bins=np.arange(0, 20, 0.1), histtype='step', density=True, linewidth=2)\n",
    "fig.savefig('Example_wrong_particle.pdf', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b0c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = priors.get_unirom_prior_1d(cryosbi.get_max_index()).sample((num_samples_umap,))\n",
    "images_wrong_particle = torch.stack([cryosbi.simulator(index) for index in indices], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cd2cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples = []\n",
    "with torch.no_grad():\n",
    "    for batched_images in torch.split(images_wrong_particle, split_size_or_sections=batch_size_sampling, dim=0):\n",
    "        samples = estimator.sample(\n",
    "            batched_images.cuda(non_blocking=True),\n",
    "            shape=(num_samples_posterior,)\n",
    "        ).cpu()\n",
    "        theta_samples.append(samples.reshape(-1, batch_size_sampling))\n",
    "samples = torch.cat(theta_samples, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd836ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(samples[:, :20].numpy(), bins=np.arange(0, 20, 0.1), histtype='step', density=True, label=name, linewidth=2)\n",
    "plt.xlabel('Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7551b40f-6d36-435d-adfb-5a047d9c1d02",
   "metadata": {},
   "source": [
    "## Detecting model missspecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2aaccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_mstar = [\n",
    "    images_no_particle,\n",
    "    images_wrong_particle,\n",
    "    images_wrong_row,\n",
    "    images_wrong_snr\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_repr_mstar = []\n",
    "with torch.no_grad():\n",
    "    for images in images_mstar:\n",
    "        latent_space_samples = []\n",
    "        for batched_images in torch.split(images, split_size_or_sections=batch_size_latent, dim=0):\n",
    "            samples = estimator.embedding(\n",
    "                batched_images.cuda(non_blocking=True)\n",
    "            ).cpu()\n",
    "            latent_space_samples.append(samples.reshape(batch_size_latent, -1))\n",
    "        latent_repr_mstar.append(torch.cat(latent_space_samples, dim=0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77897236",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryosbi = CryoEmSimulator(data_dir + \"image_params_snr01_128.json\")\n",
    "indices = priors.get_unirom_prior_1d(cryosbi.get_max_index()).sample((num_samples_umap,))\n",
    "images = torch.stack([cryosbi.simulator(index) for index in indices], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c042fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_samples = []\n",
    "batch_size = 1000\n",
    "with torch.no_grad():\n",
    "    for batched_images in torch.split(images, split_size_or_sections=batch_size_latent, dim=0):\n",
    "        samples = estimator.embedding(batched_images.cuda(non_blocking=True)).cpu()\n",
    "        latent_space_samples.append(samples.reshape(batch_size_latent, -1))\n",
    "latent_repr_m = torch.cat(latent_space_samples, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta_samples = []\n",
    "with torch.no_grad():\n",
    "    for batched_images in torch.split(images, split_size_or_sections=batch_size_sampling, dim=0):\n",
    "        samples = estimator.sample(batched_images.cuda(non_blocking=True), shape=(num_samples_posterior,)).cpu()\n",
    "        theta_samples.append(samples.reshape(-1, batch_size_sampling))\n",
    "samples = torch.cat(theta_samples, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_quantiles = np.quantile(samples.numpy(), [0.025, 0.975], axis=0)\n",
    "confidence_widths = posterior_quantiles[1] - posterior_quantiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe57459",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_latent_samples = torch.cat((latent_repr_m, *latent_repr_mstar))\n",
    "\n",
    "labels = torch.cat(\n",
    "    (\n",
    "    torch.zeros(10000),\n",
    "    1 * torch.ones(10000),\n",
    "    2 * torch.ones(10000),\n",
    "    3 * torch.ones(10000),\n",
    "    4 * torch.ones(10000)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91600e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP(metric='euclidean', n_components=2,  n_neighbors=50)\n",
    "embedding = reducer.fit_transform(cat_latent_samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7aab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Ground truth', 'No particle', 'Wrong particle', 'Wrong row (4)', 'Wrong SNR (0.03)']\n",
    "colors = ['red', 'blue', 'green', 'yellow', 'black']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "for idx, i in enumerate(range(0, (len(images_mstar) + 1) * num_samples_umap, num_samples_umap)):\n",
    "    axes[0].scatter(\n",
    "        embedding[i:i+num_samples_umap, 0],\n",
    "        embedding[i:i+num_samples_umap, 1],\n",
    "        label=name[idx], c=colors[idx],\n",
    "        s=0.1\n",
    "    )\n",
    "axes[0].legend(fontsize=10, markerscale=10)\n",
    "axes[0].set_ylabel('UMAP dimsenion 1')\n",
    "\n",
    "im1 = axes[1].scatter(\n",
    "    embedding[0:num_samples_umap, 0],\n",
    "    embedding[0:num_samples_umap, 1],\n",
    "    c=indices.numpy(),\n",
    "    s=0.5,\n",
    "    cmap='viridis'\n",
    ")\n",
    "fig.colorbar(im1, ax=axes[1], label='Index')\n",
    "axes[1].set_xlabel('UMAP dimsenion 2')\n",
    "\n",
    "im2 = axes[2].scatter(\n",
    "    embedding[0:num_samples_umap, 0],\n",
    "    embedding[0:num_samples_umap, 1],\n",
    "    c=confidence_widths,\n",
    "    s=0.5, \n",
    "    cmap='viridis'\n",
    ")\n",
    "fig.colorbar(im2, ax=axes[2], label='Width of 95% confidence intervall')\n",
    "plt.savefig(f'UMAP_analysis_{file_name}.png', dpi=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryo_sbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1391d301e9aa4dc24331c4a52095d8473e5107d84c03241f78234deb9fd2437e"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
