{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "\n",
    "# MD Stuff\n",
    "import MDAnalysis as mda\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# SBI\n",
    "import torch\n",
    "import sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi.utils.get_nn_models import posterior_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_quat(size):\n",
    "    #Sonya's code\n",
    "    \n",
    "    # np.random.seed(0)\n",
    "    quaternions = np.zeros((size, 4))\n",
    "    count = 0\n",
    "\n",
    "    while count < size:\n",
    "\n",
    "        quat = np.random.uniform(-1,1,4) #note this is a half-open interval, so 1 is not included but -1 is\n",
    "        norm = np.sqrt(np.sum(quat**2))\n",
    "\n",
    "        if ( 0.2 <= norm <= 1.0 ):\n",
    "            quaternions[count] = quat/norm\n",
    "            count += 1\n",
    "\n",
    "    return quaternions\n",
    "\n",
    "def gen_img(coord, n_pixels, pixel_size, sigma):\n",
    "    \n",
    "    n_atoms = coord.shape[1]\n",
    "    norm =  (2 * np.pi * sigma**2 * n_atoms)\n",
    "\n",
    "    grid_min = -pixel_size * (n_pixels - 1)*0.5\n",
    "    grid_max = pixel_size * (n_pixels - 1)*0.5 + pixel_size\n",
    "\n",
    "    grid = np.arange(grid_min, grid_max, pixel_size)\n",
    "\n",
    "    gauss = np.exp( -0.5 * ( ((grid[:,None] - coord[0,:])/sigma)**2) )[:,None] * \\\n",
    "            np.exp( -0.5 * ( ((grid[:,None] - coord[1,:])/sigma)**2) )\n",
    "\n",
    "    Icalc = gauss.sum(axis=2)\n",
    "\n",
    "    return Icalc/norm\n",
    "\n",
    "def load_model(fname, filter = \"name CA\"):\n",
    "\n",
    "    mda_model = mda.Universe(fname)\n",
    "\n",
    "    # Center model\n",
    "    mda_model.atoms.translate(-mda_model.select_atoms('all').center_of_mass())\n",
    "\n",
    "    # Extract coordinates\n",
    "    coordinates = mda_model.select_atoms(filter).positions.T\n",
    "\n",
    "    return coordinates\n",
    "\n",
    "def add_noise(img, n_pixels, pixel_size, snr):\n",
    "\n",
    "    img_noise = np.asarray(img).reshape(n_pixels, n_pixels)\n",
    "    \n",
    "    rad_sq = (pixel_size * (n_pixels + 1)*0.5)**2\n",
    "\n",
    "    grid_min = -pixel_size * (n_pixels - 1)*0.5\n",
    "    grid_max = pixel_size * (n_pixels - 1)*0.5 + pixel_size\n",
    "\n",
    "    grid = np.arange(grid_min, grid_max, pixel_size)\n",
    "\n",
    "    mask = grid[None,:]**2 + grid[:,None]**2 < rad_sq\n",
    "\n",
    "    var = np.std(img[mask])\n",
    "    noise = np.random.normal(loc=0.0, scale = var, size=img.shape)\n",
    "\n",
    "    img_noise = img + noise*snr\n",
    "\n",
    "    var = np.std(img_noise)\n",
    "\n",
    "    return img_noise/var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_indices = utils.BoxUniform(low=1*torch.ones(1), high=20*torch.ones(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:25<00:00,  4.29s/it]\n"
     ]
    }
   ],
   "source": [
    "def simulator_plain_1d(index):\n",
    "\n",
    "    index1 = int(np.round(index))\n",
    "\n",
    "    coord = load_model(f\"models/state_1_{index1}.pdb\")\n",
    "\n",
    "    \"\"\" \n",
    "    # Uncomment if you want rotations\n",
    "    quat = gen_quat(1)[0]\n",
    "    rot_mat = Rotation.from_quat(quat).as_matrix()\n",
    "    coord = np.matmul(rot_mat, coord)\n",
    "    \"\"\"\n",
    "\n",
    "    N_PIXELS = 32\n",
    "    PIXEL_SIZE = 4\n",
    "    SIGMA = 1\n",
    "    IMG_PARAMS = (N_PIXELS, PIXEL_SIZE, SIGMA)\n",
    "\n",
    "    image = gen_img(coord, *IMG_PARAMS)\n",
    "    \n",
    "    # Uncomment if you want noise\n",
    "    # SNR = 10\n",
    "    image = add_noise(image, N_PIXELS, PIXEL_SIZE, SNR)\n",
    "\n",
    "    return image\n",
    "\n",
    "sim_plain_1d, prior_1d = prepare_for_sbi(simulator_plain_1d, prior_indices_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing of the generated images \n",
    "\n",
    "Because we are generating images with no rotations we need to add noise so pytorch doesn't die. This could also be the place to normalize images, or add the CTF. I prefer not to do add these things when generating the images because having a set of raw images allows me to do many test with just one dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SBI's neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_estimator_build_fun = posterior_nn(model='maf', hidden_features=10, num_transforms=4)\n",
    "inference = SNPE(prior=prior_indices, density_estimator=density_estimator_build_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (/home/david/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1204175)",
      "at /home/david/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (/home/david/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223212)",
      "at v.dispose (/home/david/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1216694)",
      "at /home/david/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533674",
      "at t.swallowExceptions (/home/david/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:913059)",
      "at dispose (/home/david/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533652)",
      "at t.RawSession.dispose (/home/david/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "# Calculate and save posterior\n",
    "inference = inference.append_simulations(indices, images)\n",
    "density_estimator = inference.train()\n",
    "posterior_0 = inference.build_posterior(density_estimator)\n",
    "\n",
    "with open(\"posteriors/posterior_no_rot_norm.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(posterior_0, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or load it\n",
    "with open(\"posteriors/posterior_no_rot.pkl\", \"rb\") as handle:\n",
    "    posterior_0 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the posterior trained well with one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prior_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_141445/2411173241.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrue_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprior_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrue_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulate_for_sbi_cpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ranks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs_per_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prior_indices' is not defined"
     ]
    }
   ],
   "source": [
    "true_index = prior_indices.sample((1,))\n",
    "true_index, true_images = simulate_for_sbi_cpp(indices, args_dict, n_ranks=4, n_threads=1, imgs_per_index=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1aacc329f4eedc97866ad18b95bb07bba41681494da4fd1f5a311cb8e4006de"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('sbi_cryoem')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
