{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import json\n",
    "import mrcfile\n",
    "import umap\n",
    "\n",
    "from cryo_sbi.inference.models import build_models\n",
    "from cryo_sbi import CryoEmSimulator\n",
    "from cryo_sbi.inference import priors\n",
    "import cryo_sbi.utils.estimator_utils as est_utils\n",
    "from cryo_sbi.utils.image_utils import (\n",
    "    LowPassFilter,\n",
    "    NormalizeIndividual,\n",
    "    MRCtoTensor,\n",
    "    FourierDownSample,\n",
    "    Mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load posterior surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_config_file = (\n",
    "    \"../experiments/6wxb/resnet18_fft_encoder.json\"  # \"PATH_TO_NN_CONFIG\"\n",
    ")\n",
    "posterior_weights_file = (\n",
    "    \"../experiments/6wxb/6wxb_mixed_posterior.estimator\"  # \"PATH_TO_NN_WEIGHTS\"\n",
    ")\n",
    "\n",
    "estimator = est_utils.load_estimator(\n",
    "    posterior_config_file, posterior_weights_file, device=device\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test posterior with simulated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_config_file = \"PATH_TO_IMAGE_CONFIG\"\n",
    "cryo_em = CryoEmSimulator(image_config_file)\n",
    "cryo_em.config[\"SNR\"] = 0.05  # Fixing the SNR, set range with [lower, upper]\n",
    "cryo_em.config[\"SIGMA\"] = 5.0  # Fixing the Sigma, set range with [lower, upper]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate a single image and infer the conformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_image = cryo_em.simulator(torch.tensor([50.0]))\n",
    "samples = est_utils.sample_posterior(\n",
    "    estimator, synthetic_image.unsqueeze(0), num_samples=10000, device=device\n",
    ")  # we need to use unsqueeze becase we are using a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "_ = ax[0].imshow(synthetic_image)\n",
    "_ = ax[1].hist(samples.flatten(), bins=np.linspace(0, cryo_em.max_index, 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test posterior on 20 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.tensor(np.arange(0, cryo_em.max_index + 1, 5), dtype=float).reshape(\n",
    "    -1, 1\n",
    ")\n",
    "images = torch.stack([cryo_em.simulator(index) for index in indices], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = est_utils.sample_posterior(\n",
    "    estimator, images, num_samples=10000, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(10, 8))\n",
    "for idx, ax in enumerate(axes.reshape(-1)):\n",
    "    ax.imshow(images[idx], vmax=4, vmin=-4, cmap=\"binary\")\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.text(10, 20, str(int(indices[idx].item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(10, 8), sharex=True)\n",
    "for idx, ax in enumerate(axes.reshape(1, -1)[0]):\n",
    "    ax.hist(\n",
    "        samples[:, idx].flatten().numpy(),\n",
    "        bins=np.arange(0, 100, 1),\n",
    "        histtype=\"step\",\n",
    "        color=\"blue\",\n",
    "        label=\"all\",\n",
    "    )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks(range(0, 100, 20))\n",
    "    ax.axvline(indices[idx], color=\"red\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you want we can also test the posterior with SBCC (This may take a while)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lampe.data import JointLoader\n",
    "from lampe.diagnostics import expected_coverage_mc\n",
    "from lampe.plots import coverage_plot\n",
    "from cryo_sbi.inference import priors\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = JointLoader(\n",
    "    priors.get_uniform_prior_1d(cryo_em.max_index),\n",
    "    cryo_em.simulator,\n",
    "    vectorized=False,\n",
    "    batch_size=1,\n",
    "    num_workers=24,  # You might wanna change this\n",
    "    prefetch_factor=1,\n",
    ")\n",
    "\n",
    "levels, coverages = expected_coverage_mc(\n",
    "    estimator.flow,\n",
    "    (\n",
    "        (estimator.standardize(theta.cuda()), x.cuda())\n",
    "        for theta, x in islice(loader, 500)\n",
    "    ),  # We use here just 500 samples, this is not really accurate but gives us an idea\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_plot(levels, coverages);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's look at experimental images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use parts of the torchvision module to take care of imigae processing\n",
    "# We can build a transformation which modify our images in a predefined pipline\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        MRCtoTensor(),  # Load mrc file (str) and construct pytorch tensor\n",
    "        transforms.Resize(size=(128, 128)),  # Resize image to given size\n",
    "        NormalizeIndividual(),  # Normalize image\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Example transformation, we can do more then just normalization\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        MRCtoTensor(),\n",
    "        FourierDownSample(256, 128),\n",
    "        NormalizeIndividual(),\n",
    "        Mask(128, 45),\n",
    "        LowPassFilter(128, 80),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the particles directly here : https://www.ebi.ac.uk/empiar/EMPIAR-10532/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_images = transform(\n",
    "    \"../../6wxb/particles/particles_01.mrc\"\n",
    ")  # Here the images are loaded, resized and normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want to load more than just one mrc file\n",
    "experimental_images = []\n",
    "for i in range(1, 17):\n",
    "    if i < 10:\n",
    "        img_file = f\"../../6wxb/particles/particles_0{i}.mrc\"\n",
    "    else:\n",
    "        img_file = f\"../../6wxb/particles/particles_{i}.mrc\"\n",
    "    tmp_images = transform(img_file)\n",
    "    experimental_images.append(tmp_images)\n",
    "\n",
    "experimental_images = torch.cat(experimental_images, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(10, 8))\n",
    "for idx, ax in enumerate(axes.reshape(-1)):\n",
    "    ax.imshow(experimental_images[idx], vmax=4, vmin=-4, cmap=\"binary\")\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally we test the posterior on the real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_exp = est_utils.sample_posterior(\n",
    "    estimator, experimental_images, num_samples=10000, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(10, 8), sharex=True)\n",
    "for idx, ax in enumerate(axes.reshape(1, -1)[0]):\n",
    "    ax.hist(\n",
    "        samples_exp[:, idx].flatten().numpy(),\n",
    "        bins=np.arange(0, 100, 1),\n",
    "        histtype=\"step\",\n",
    "        color=\"blue\",\n",
    "        label=\"all\",\n",
    "    )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks(range(0, 100, 20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since we can look at all posteriors, lets look at all the posterior means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean = samples_exp.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(posterior_mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some of the posterior might be to wide, so lets exclude them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_quantiles = np.quantile(samples_exp.numpy(), [0.025, 0.975], axis=0)\n",
    "confidence_widths = (posterior_quantiles[1] - posterior_quantiles[0]).flatten()\n",
    "condition = (\n",
    "    confidence_widths < 50\n",
    ")  # Select posterior with a 95% confidence intervall less the 50 indices\n",
    "posterior_idx = np.where(condition)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(10, 8), sharex=True)\n",
    "for idx, ax in enumerate(axes.reshape(1, -1)[0]):\n",
    "    ax.hist(\n",
    "        samples_exp[:, posterior_idx[idx]].flatten().numpy(),\n",
    "        bins=np.arange(0, 100, 1),\n",
    "        histtype=\"step\",\n",
    "        color=\"blue\",\n",
    "        label=\"all\",\n",
    "    )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks(range(0, 100, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean = samples_exp[:, posterior_idx].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(posterior_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryo_sbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1391d301e9aa4dc24331c4a52095d8473e5107d84c03241f78234deb9fd2437e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
