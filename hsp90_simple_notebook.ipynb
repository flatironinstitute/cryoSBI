{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "\n",
    "# MD Stuff\n",
    "import MDAnalysis as mda\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# SBI\n",
    "import torch\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi.utils.get_nn_models import posterior_nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for generating images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_quat(size):\n",
    "    #Sonya's code\n",
    "    \n",
    "    #np.random.seed(0)\n",
    "    quaternions = np.zeros((size, 4))\n",
    "    count = 0\n",
    "\n",
    "    while count < size:\n",
    "\n",
    "        quat = np.random.uniform(-1,1,4) #note this is a half-open interval, so 1 is not included but -1 is\n",
    "        norm = np.sqrt(np.sum(quat**2))\n",
    "\n",
    "        if ( 0.2 <= norm <= 1.0 ):\n",
    "            quaternions[count] = quat/norm\n",
    "            count += 1\n",
    "\n",
    "    return quaternions\n",
    "\n",
    "def gen_img(coord, args_dict):\n",
    "    \n",
    "    n_atoms = coord.shape[1]\n",
    "    norm = 1 / (2 * np.pi * args_dict[\"SIGMA\"]**2 * n_atoms)\n",
    "\n",
    "    grid_min = -args_dict[\"PIXEL_SIZE\"] * (args_dict[\"N_PIXELS\"] - 1)*0.5\n",
    "    grid_max = args_dict[\"PIXEL_SIZE\"] * (args_dict[\"N_PIXELS\"] - 1)*0.5 + args_dict[\"PIXEL_SIZE\"]\n",
    "\n",
    "    grid = np.arange(grid_min, grid_max, args_dict[\"PIXEL_SIZE\"])\n",
    "\n",
    "    gauss = np.exp( -0.5 * ( ((grid[:,None] - coord[0,:]) / args_dict[\"SIGMA\"])**2) )[:,None] * \\\n",
    "            np.exp( -0.5 * ( ((grid[:,None] - coord[1,:]) / args_dict[\"SIGMA\"])**2) )\n",
    "\n",
    "    image = gauss.sum(axis=2) * norm\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_model(fname, filter = \"name CA\"):\n",
    "\n",
    "    mda_model = mda.Universe(fname)\n",
    "\n",
    "    # Center model\n",
    "    mda_model.atoms.translate(-mda_model.select_atoms('all').center_of_mass())\n",
    "\n",
    "    # Extract coordinates\n",
    "    coordinates = mda_model.select_atoms(filter).positions.T\n",
    "\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for post-processing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img, n_pixels, pixel_size, snr):\n",
    "\n",
    "    img_noise = np.asarray(img).reshape(n_pixels, n_pixels)\n",
    "    \n",
    "    rad_sq = (pixel_size * (n_pixels + 1)*0.5)**2\n",
    "\n",
    "    grid_min = -pixel_size * (n_pixels - 1)*0.5\n",
    "    grid_max = pixel_size * (n_pixels - 1)*0.5 + pixel_size\n",
    "\n",
    "    grid = np.arange(grid_min, grid_max, pixel_size)\n",
    "\n",
    "    mask = grid[None,:]**2 + grid[:,None]**2 < rad_sq\n",
    "\n",
    "    noise_std = np.std(img[mask]) / snr\n",
    "    noise = np.random.normal(loc=0.0, scale = noise_std, size=img.shape)\n",
    "\n",
    "    img_noise = img + noise\n",
    "\n",
    "    return img_noise\n",
    "\n",
    "def add_noise_to_dataset(dataset, args_dict, snr):\n",
    "\n",
    "    images_with_noise = torch.empty_like(dataset)\n",
    "\n",
    "    for i in range(dataset.shape[0]):\n",
    "\n",
    "        image_with_noise = add_noise(\n",
    "            dataset[i].reshape(args_dict[\"N_PIXELS\"], args_dict[\"N_PIXELS\"]).numpy(),\n",
    "            args_dict[\"N_PIXELS\"],\n",
    "            args_dict[\"PIXEL_SIZE\"],\n",
    "            snr)\n",
    "\n",
    "        images_with_noise[i] = torch.tensor(image_with_noise.reshape(args_dict[\"N_PIXELS\"]**2))\n",
    "\n",
    "    return images_with_noise\n",
    "\n",
    "def normalize_dataset(dataset):\n",
    "\n",
    "    norm_images = torch.empty_like(dataset)\n",
    "\n",
    "    for i in range(dataset.shape[0]):\n",
    "\n",
    "        mu = torch.mean(dataset[i])\n",
    "        sigma = torch.std(dataset[i])\n",
    "\n",
    "        norm_images[i] = (dataset[i] - mu) / sigma\n",
    "\n",
    "    return norm_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating data\n",
    "\n",
    "I only generate images for models with name ```models/state_1_*.txt```. If you want to generate different models change the 43rd line in ```simulate_for_sbi_cpp``` (one cell above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_indices = utils.BoxUniform(low=1*torch.ones(1), high=20*torch.ones(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\"PIXEL_SIZE\": 4,\n",
    "             \"N_PIXELS\": 32,\n",
    "             \"SIGMA\": 1.0\n",
    "             }\n",
    "\n",
    "def simulator(index):\n",
    "\n",
    "    index1 = int(np.round(index))\n",
    "\n",
    "    coord = load_model(f\"models/state_1_{index1}.pdb\")\n",
    "\n",
    "    # quat = gen_quat(1)[0]\n",
    "    # rot_mat = Rotation.from_quat(quat).as_matrix()\n",
    "    # coord = np.matmul(rot_mat, coord)\n",
    "\n",
    "    image = gen_img(coord, args_dict)\n",
    "\n",
    "    return image\n",
    "\n",
    "simulator_sbi, prior_sbi = prepare_for_sbi(simulator, prior_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running 1000 simulations in 1000 batches.: 100%|██████████| 1000/1000 [01:07<00:00, 14.79it/s]\n"
     ]
    }
   ],
   "source": [
    "indices, images = simulate_for_sbi(\n",
    "    simulator_sbi,\n",
    "    proposal=prior_sbi,\n",
    "    num_simulations=1000,\n",
    "    num_workers=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing of the generated images \n",
    "\n",
    "Because we are generating images with no rotations we need to add noise so pytorch doesn't die. This could also be the place to normalize images, or add the CTF. I prefer not to do add these things when generating the images because having a set of raw images allows me to do many test with just one dataset.\n",
    "\n",
    "### WARNING: with images without rotations the lack of noise kills PyTorch!\n",
    "\n",
    "I post-process images on-the-fly to save memory (see 2 cells below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SBI's neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_estimator_build_fun = posterior_nn(model='maf', hidden_features=10, num_transforms=4)\n",
    "inference = SNPE(prior=prior_indices, density_estimator=density_estimator_build_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Data/Packages/Research/miniconda3/envs/sbi_cryoem/lib/python3.8/site-packages/sbi/neural_nets/flow.py:108: UserWarning: In one-dimensional output space, this flow is limited to Gaussians\n",
      "  warn(f\"In one-dimensional output space, this flow is limited to Gaussians\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network successfully converged after 80 epochs.\n"
     ]
    }
   ],
   "source": [
    "# Calculate and save posterior\n",
    "posteriors = {}\n",
    "\n",
    "# Train multiple posteriors for different noise levels\n",
    "snr_training = [0.1]\n",
    "\n",
    "for snr in snr_training:\n",
    "    \n",
    "    ##### Post processing images #####\n",
    "    images_with_noise = add_noise_to_dataset(images, args_dict, snr) \n",
    "    images_with_noise = normalize_dataset(images_with_noise)\n",
    "    ##### Post processing images #####\n",
    "    \n",
    "    inference = inference.append_simulations(indices, images_with_noise)\n",
    "\n",
    "    density_estimator = inference.train()\n",
    "    posteriors[f\"snr_{snr}\"] = inference.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"posteriors_no_rot.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(posteriors, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"posteriors_no_rot.pkl\", \"rb\") as handle:\n",
    "    posteriors = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_index = prior_sbi.sample((1,))\n",
    "true_image = simulator_sbi(true_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Drawing 20000 posterior samples: 23314it [00:00, 41928.40it/s]                           \n"
     ]
    }
   ],
   "source": [
    "n_samples = 20000\n",
    "\n",
    "snrs_testing = [0.1]\n",
    "\n",
    "samples = torch.empty((len(snrs_testing), n_samples, 1))\n",
    "\n",
    "for i, snr in enumerate(snrs_testing):\n",
    "    \n",
    "    true_image_with_noise = add_noise_to_dataset(true_image, args_dict, snr) \n",
    "    #true_image_with_noise = normalize_dataset(true_image_with_noise)\n",
    "    samples[i] = posteriors[f\"snr_{snr}\"].sample((n_samples,), x=true_image_with_noise)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = analysis.pairplot(samples[0],\n",
    "                           limits=[[1,21], [1,21]],\n",
    "                           #ticks=[[2,10], [2,10]],\n",
    "                           figsize=(5,5),\n",
    "                           points=true_index.round(),\n",
    "                           points_offdiag={'markersize': 6},\n",
    "                           points_colors='r');"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1aacc329f4eedc97866ad18b95bb07bba41681494da4fd1f5a311cb8e4006de"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('sbi_cryoem')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
